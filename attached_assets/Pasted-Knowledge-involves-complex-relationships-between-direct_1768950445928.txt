Knowledge involves complex relationships between direct awareness, inferential reasoning, and causal/logical dependence-relations, with legitimate inference rules corresponding to genuine dependence structures in reality.

I distinguish between direct and indirect knowledge based on how we acquire beliefs. Direct knowledge comes without inference—when I see a red apple before me, I know directly that there is a red object present. Indirect knowledge requires inference from other beliefs I already hold.

This distinction matters because inference itself depends on rules that must correspond to real dependence-relations in the world. When I infer that smoke indicates fire, my inference succeeds only because there exists a genuine causal dependence-relation between fire and smoke. "The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships."

Not all inference rules are legitimate. A rule counts as legitimate only when it tracks actual dependence structures. Consider modus ponens: from P and (P→Q), we infer Q. This rule works because it corresponds to a logical dependence-relation that holds among propositions themselves.

The key insight is that dependence-relations come in two fundamental types: logical and causal. Logical dependence-relations hold among propositions based on their logical structure. If I know that all ravens are black and that Tweety is a raven, then the proposition "Tweety is black" depends logically on these premises.

Causal dependence-relations operate differently. They connect states of affairs in the physical world, not propositions. When lightning causes thunder, we have a causal dependence-relation between two events. My knowledge of this relation comes through sensory experience, not logical analysis.

This creates an epistemological asymmetry. I can know some logical dependence-relations through conceptual analysis alone. "There is a certainty that can attach to knowledge of what we are consciously thinking that cannot attach to knowledge of the external world." But causal relations require empirical investigation.

Consider how formal logic works. "Knowledge is parasitic on one's knowledge of informal analytic truths. This has nothing to do with the idiosyncrasies of human psychology. It's an epistemological consequence of a strictly logical point." When I accept that ‹(P and (P→Q))→Q› holds for all instances, I'm relying on the informal truth that "given any two propositions P and Q, ‹(P and (P→Q))→Q›."

The formal statement "if snow is white, and (if snow is white then snow is not pink), then snow is not pink" can be accepted for two reasons. Either I recognize it as an instance of modus ponens, or I verify it through some other means. If I accept it as an instance of modus ponens, then "one's acceptance of (3), under those circumstances embodies knowledge of an informal truth."

This shows that even our most rigorous formal reasoning depends on informal knowledge of dependence-relations. The rules of inference we use in logic and science must track real structures in reality, whether logical or causal, to generate genuine knowledge rather than mere belief.This brings me to a crucial point about the nature of inference rules themselves. Not all inference rules are legitimate, and the distinction between legitimate and illegitimate rules corresponds precisely to whether they track genuine dependence-relations in reality.

Consider how "axiomatization of a discipline is what results when it is successfully axiomatized." The goal is "to identify a small number of propositions and a small number of inference-rules such that all of the results of that discipline follow from those propositions by means of those inference rules." But this enterprise only succeeds when the inference rules correspond to actual dependence structures.

In logical contexts, legitimate inference rules track logical dependence-relations. Modus ponens works because there really is a logical dependence between ‹P and (P→Q)› and ‹Q›. The rule doesn't create this dependence - it reflects it. "The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships."

The same principle applies to causal inference. "Causal inference: An inference based on knowledge of a causal law (e.g., I see smoke; I know that there is smoke only if there is fire; so I infer that there is, or was, a fire)." This inference is legitimate only because there exists a genuine causal dependence-relation between fire and smoke.

But here's where things get complicated. "Different Consequence Relations" shows us that "the relation that p bears to phi of p may otherwise be very different from the relation that psi of p bears to p, even though both are consequence relations." Not all consequence relations have the same epistemic status or the same grounding in reality.

Some inference rules fail because they don't track any genuine dependence-relation at all. Others fail because they conflate different types of dependence-relations. A rule that treats logical necessity as if it were causal necessity, or vice versa, will generate false beliefs rather than knowledge.

This is why I insist that legitimate inference rules must be grounded in our understanding of the specific type of dependence-relation they're meant to track. We can't simply stipulate inference rules and expect them to generate knowledge. The rules must correspond to the actual structure of logical or causal dependence in the domain we're investigating.

"Pro-state lies" emerge when inference rules are used without proper grounding in dependence-relations. The resulting conclusions may seem to follow logically, but they don't constitute genuine knowledge because they're not tracking real structures in reality.The distinction between logical and causal dependence-relations is fundamental to understanding how different types of inference generate knowledge. Logical dependence-relations hold among propositions in virtue of their logical structure alone. When I know that all bachelors are unmarried men, this knowledge doesn't depend on any empirical investigation of the world.

Causal dependence-relations, by contrast, hold among states of affairs in the physical world. "The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships." The regularities we observe are manifestations of underlying causal structures, not the structures themselves.

This distinction matters because the two types of dependence-relations require completely different epistemic approaches. Logical dependence-relations can be known through conceptual analysis alone. "Given any open-sentence (or open-proposition) all of whose instances are true, for example: (1) ‹(P and (P→Q))→Q›, the fact that it's true for all its instances is a consequence of the fact that some informal truth holds."

Causal dependence-relations can only be established through sensory experience. I cannot determine through conceptual analysis alone whether fire causes smoke. This requires empirical investigation of the physical world and observation of actual causal processes.

The failure to respect this distinction leads to systematic errors in reasoning. "Incoherence arises from trying to satisfy two incompatible systems" - and treating logical dependence as if it were causal dependence, or vice versa, creates exactly this kind of incoherence.

Consider how this plays out in scientific reasoning. When I infer that a particular fire will produce smoke, I'm relying on my knowledge of a causal dependence-relation. But when I infer that if all fires produce smoke and this is a fire, then this will produce smoke, I'm relying on logical dependence-relations embedded in the structure of universal quantification.

"First of all, laws are not expressed by regularities. A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge." This shows why causal dependence-relations are more complex than simple regularities. The causal structure involves dispositions and tendencies, not exceptionless correlations.

Logical dependence-relations, by contrast, are necessary and exceptionless within their domain. If P logically implies Q, then whenever P is true, Q must be true. There are no exceptions, no threshold effects, no interfering factors.

This is why "calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations." The calculator's physical processes embody logical dependence-relations even though the machine itself doesn't grasp those relations conceptually.The distinction between propositions as objects of knowledge and non-propositional awareness reveals another fundamental layer in the architecture of knowledge. I can be aware of a rock without knowing any propositions about it. This objectual awareness doesn't constitute knowledge in the strict sense.

"There is a certainty that can attach to knowledge of what we are consciously thinking that cannot attach to knowledge of the external world." This captures something crucial about propositional awareness. When I know that snow is white, I'm aware of a proposition - a truth that can be articulated conceptually.

Non-propositional awareness operates differently. I can see a tree, hear a sound, or feel pain without formulating any propositions about these experiences. This awareness is direct but not conceptually structured. It provides the raw material for knowledge but isn't itself knowledge.

Propositions, by contrast, are the proper objects of knowledge because they can be true or false. "If snow is white, and (if snow is white then snow is not pink), then snow is not pink" - this is a proposition I can know to be true. The tree I see isn't true or false; it simply exists.

This distinction matters because knowledge requires conceptual articulation. "Creatures in whom there are no 'occult processes' are zombies, and zombies cannot be acculturated." Without the capacity for propositional thought, there can be no genuine knowledge, only stimulus-response patterns.

Consider what happens when I observe a scientific experiment. My visual awareness of the apparatus and readings is non-propositional. But my knowledge that the temperature is 100 degrees Celsius involves grasping the proposition that the thermometer reads 100 degrees.

The transition from objectual awareness to propositional knowledge involves conceptualization. I must apply concepts like 'temperature' and 'degrees Celsius' to transform my raw awareness into articulable knowledge. This conceptualization is what makes inference possible.

"In the final analysis, Chomsky and Kant say that, give or take a few nuances, we are born knowing everything we will ever know." This overstates the case, but it points to something important: the conceptual frameworks that enable propositional knowledge must be available to the knower.

Without concepts, I might have rich objectual awareness but no knowledge properly speaking. The concepts provide the structure that allows me to formulate propositions and recognize their truth-values. They transform mere awareness into the kind of articulated understanding that can serve as premises for inference.

This is why theoretical knowledge is necessarily propositional. I cannot have non-propositional knowledge of quantum mechanics or evolutionary theory. These domains exist only as structured sets of propositions related by logical and evidential dependence-relations.

"If a given object's length is given by an irrational number, that object's length cannot be established by measuring that object." This shows how propositional knowledge can transcend the limitations of direct objectual awareness. Through conceptual analysis and mathematical reasoning, I can know truths that no amount of direct observation could establish.

The relationship between these two forms of awareness is asymmetric. Propositional knowledge often depends on objectual awareness as its source, but objectual awareness doesn't depend on propositional knowledge. I can see without knowing, but I cannot know without concepts.Conceptual analysis reveals a crucial feature of knowledge: some dependence-relations can be known through pure conceptual work, without any appeal to sensory experience. When I analyze the concept of a circle, I discover that being a closed planar figure of uniform curvature is analytically connected to being circular. This isn't empirical discovery—it's conceptual unpacking.

"Joe obviously doesn't have to do empirical work to arrive at a correct analysis of this concept – to arrive at the knowledge that a circle is a closed planar figure of uniform curvature." The dependence-relation here is logical, not causal. The proposition that something is circular logically depends on the proposition that it has uniform curvature, and this dependence can be known through conceptual analysis alone.

This creates a fundamental division in how we know dependence-relations. Logical dependence-relations among propositions can be known analytically, while causal dependence-relations among states of affairs require empirical investigation. I can know that modus ponens is valid without consulting experience, but I cannot know that fire causes smoke without observing the world.

"Knowledge is parasitic on one's knowledge of informal analytic truths. This has nothing to do with the idiosyncrasies of human psychology. It's an epistemological consequence of a strictly logical point." My knowledge of formal logical truths depends on my grasp of informal principles that govern logical relationships generally.

Consider the inference rule modus ponens. I know this rule is legitimate because I understand the informal truth that, given any two propositions P and Q, if P is true and P implies Q, then Q must be true. This informal principle isn't itself formally expressible—it's a meta-logical truth about the nature of logical dependence.

"(2) given any two propositions P and Q, ‹(P and (P→Q))→Q›). It must be stressed that (2) is an informal truth." The formal rule derives its legitimacy from this informal understanding of logical necessity. Without grasping the informal principle, I couldn't recognize why the formal rule works.

This reveals something important about the structure of knowledge. My understanding of legitimate inference rules rests on conceptual analysis of dependence-relations themselves. I don't learn that modus ponens is valid by observing its success in particular cases—I recognize its validity by analyzing what logical dependence means.

The same pattern holds for mathematical knowledge. When I prove that the square root of 2 is irrational, I'm not discovering an empirical fact about numbers. I'm unpacking the logical consequences of the concepts involved—rational number, square root, and so forth.

"In principle, anyone who grasps that concept could arrive at a correct analysis of it without doing empirical work." The phrase "in principle" here means given sufficient conceptual sophistication and logical acuity. The limitations are cognitive, not epistemological.

This shows why some knowledge is necessarily a priori. The dependence-relations that structure logical and mathematical domains aren't contingent features of the world that could be otherwise. They're constitutive of what it means for propositions to stand in logical relationships at all.The distinction between propositional and objectual awareness becomes crucial here. I can have objectual awareness of a rock or tree without any conceptual articulation whatsoever. This is direct sensory contact with objects in my environment. But such objectual awareness cannot constitute knowledge in any meaningful sense.

Knowledge requires propositional awareness—conceptually articulated awareness that can be true or false. When I know that the rock is granite, I'm not merely aware of the rock as an object. I'm aware of the proposition that this rock has granite composition, and I hold this proposition to be true on some evidential basis.

"There is a certainty that can attach to knowledge of what we are consciously thinking that cannot attach to knowledge of the external world." This asymmetry reflects the different roles observation plays in different domains of knowledge. My access to my own mental states is direct and conceptually immediate. But my knowledge of external objects necessarily involves causal processes linking those objects to my sensory apparatus.

Observation functions differently depending on whether we're dealing with logical dependence-relations or causal ones. When I observe that modus ponens preserves truth, I'm not conducting an empirical investigation. I'm recognizing a logical relationship through conceptual analysis. The "observation" here is purely intellectual.

But when I observe that heating expands metals, I'm detecting a causal dependence-relation that holds contingently in the physical world. This requires sensory experience because causal relations can only be known through their empirical manifestations. "The physical world is characterized by many regularities. But presumably these regularities express, and do not constitute, the existence of principled relationships."

This means observational knowledge always involves inference from sensory data to conclusions about external reality. I never directly observe that the metal is expanding—I observe certain visual appearances and infer expansion from them. The inference relies on background knowledge about how expansion appears to observers like me under standard conditions.

"Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations." Similarly, my sensory apparatus doesn't directly detect external properties. But its behavior can be understood as responding systematically to external causal influences under normal circumstances.

The key insight is that observation never gives us direct propositional access to external reality. It provides sensory data that must be interpreted through conceptual frameworks. These frameworks embody our understanding of causal dependence-relations between external states of affairs and our sensory responses.

This is why observational knowledge is inherently theoretical. Even the most basic perceptual judgments involve applying concepts and drawing inferences from sensory presentations to conclusions about their external causes.

"If a given object's length is given by an irrational number, that object's length cannot be established by measuring that object." Measurement involves discrete observational procedures applied to continuous physical magnitudes. The gap between observation and reality means observational knowledge is always approximate and limited in precision.This brings us to a crucial point about theoretical knowledge: it is necessarily inferential in nature. When I claim to know that electrons exist or that DNA has a double helix structure, I am not reporting direct observations. I am drawing conclusions from complex chains of reasoning that connect observable phenomena to theoretical entities and structures.

"The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships." This distinction is fundamental to understanding theoretical knowledge. The regularities we observe don't constitute the theoretical entities themselves—they express underlying causal structures that we can only access through inference.

Consider how theoretical physics proceeds. I never directly observe quarks or electromagnetic fields. Instead, I observe patterns in bubble chambers, meter readings, and mathematical relationships. From these observations, I infer the existence of theoretical entities that would causally produce exactly these observable patterns.

The inferential nature of theoretical knowledge means it depends entirely on the legitimacy of the inference rules connecting observations to theoretical conclusions. These rules must correspond to genuine dependence-relations in reality, or the resulting "knowledge" is spurious.

"To avoid the theoretical arbitrariness associated with such a position, we must say that (#) is true exactly if there is some actual causal process beginning with E and ending with E*." Theoretical knowledge claims are only legitimate when they track real causal processes connecting theoretical entities to observable effects.

This creates a fundamental epistemological problem. How can I validate inference rules for theoretical knowledge without already having theoretical knowledge? I cannot directly compare my theoretical conclusions to theoretical reality—I can only compare predicted observations to actual observations.

The solution lies in recognizing that legitimate theoretical inference rules are those that preserve truth across the causal chains connecting theoretical entities to observable phenomena. When my theoretical framework correctly predicts novel observational consequences, this provides evidence that my inference rules track genuine causal dependence-relations.

"There is a certainty that can attach to knowledge of what we are consciously thinking that cannot attach to knowledge of the external world." This asymmetry extends to theoretical knowledge. I can be certain about the logical relationships within my theoretical framework, but the connection between framework and external reality remains forever inferential and fallible.

Theoretical knowledge thus occupies a peculiar epistemic position. It is necessarily inferential, depending on rules that connect observations to unobservable entities. Yet it aims to describe the very causal structures that make observation itself possible. This creates an inherent circularity that cannot be eliminated—only acknowledged and carefully managed through rigorous attention to the legitimacy of our inferential procedures.**Standard Conditions for Knowledge: Belief, Truth, and Justification**

The traditional analysis of knowledge requires three conditions: belief, truth, and justification. I accept this framework but insist on understanding each component through my theory of dependence-relations.

Belief involves propositional attitudes toward statements that can be true or false. "Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations." Similarly, beliefs are not themselves knowledge, but they provide the psychological foundation that makes knowledge possible.

Truth is correspondence between propositions and reality. But this correspondence must be understood through causal dependence-relations. "The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships."

The regularities I observe express underlying causal structures. Truth consists in my propositions correctly representing these structures, not merely correlating with observable patterns.

Justification is where my analysis becomes distinctive. Traditional epistemology treats justification as a relation between beliefs. I argue it must be grounded in legitimate inference rules that correspond to real dependence-relations.

"To avoid the theoretical arbitrariness associated with such a position, we must say that (#) is true exactly if there is some actual causal process beginning with E and ending with E*." Justification requires tracing actual causal processes, not merely satisfying formal logical requirements.

This creates problems for purely coherentist theories of justification. Coherence among beliefs is insufficient if those beliefs fail to track genuine dependence-relations in reality. "Incoherence arises from trying to satisfy two incompatible systems." But coherence within a single system provides no guarantee of truth without proper grounding in causal processes.

Foundationalist theories face different difficulties. They typically ground knowledge in allegedly indubitable beliefs about immediate experience. But immediate experience provides only objectual awareness, not propositional knowledge.

"If a given object's length is given by an irrational number, that object's length cannot be established by measuring that object." This illustrates the gap between direct awareness and propositional knowledge. Even basic observational beliefs require conceptual frameworks that go beyond immediate experience.

My solution combines elements of both approaches while avoiding their characteristic problems. Knowledge requires beliefs that are both causally connected to reality and logically integrated within coherent conceptual frameworks.

The causal connection ensures that our beliefs track genuine features of the world rather than mere projections of our conceptual schemes. The logical integration ensures that our individual beliefs gain support from their relationships within broader theoretical structures.

But this raises questions about the relationship between causal and logical necessity in justification. Some justificatory relationships are purely logical—they depend only on the meanings of our concepts. Others are empirical—they depend on contingent causal facts about the world.The distinction between causal and logical necessity proves crucial for understanding different types of evidence relationships. Logical necessity operates through conceptual connections that hold independently of empirical facts. When I know that all bachelors are unmarried, this knowledge depends on logical relationships among concepts, not on causal processes in the world.

"Given any two propositions P and Q, ‹(P and (P→Q))→Q›" expresses a logical dependence-relation that holds necessarily. This necessity stems from the logical structure of the propositions themselves, not from any causal mechanisms that might connect the states of affairs they describe.

Causal necessity operates differently. When I infer fire from smoke, I rely on knowledge of causal laws connecting these phenomena. "A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge." This shows that causal connections, unlike logical ones, admit of exceptions and require empirical investigation.

The evidence relationship in causal inference depends on regularities observed in experience. I cannot determine through conceptual analysis alone whether smoke indicates fire. This knowledge requires observation of actual causal processes connecting combustion and smoke production.

"First of all, laws are not expressed by regularities." The regularities we observe in experience express underlying causal structures but do not constitute them. The logical relationships among our concepts about these regularities are themselves knowable through conceptual analysis.

Consider how these two types of necessity interact in scientific reasoning. When I apply modus ponens to causal premises, I rely simultaneously on logical and causal necessity. The inference rule itself operates through logical necessity, while the causal premises describe empirically discovered regularities.

"The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships." This distinction matters for understanding evidence relationships.

Logical evidence relationships are knowable a priori through conceptual analysis. If I grasp the concepts involved in a logical inference, I can determine its validity without empirical investigation. The necessity here is absolute—it cannot be overturned by further experience.

Causal evidence relationships are knowable only a posteriori through observation. Even when I have strong evidence for a causal connection, further experience might reveal exceptions or refinements. "Laws of nature as dispositive rather than exceptionless" captures this essential difference.

This creates an asymmetry in justification. My knowledge of logical dependence-relations provides absolutely certain grounds for inference. My knowledge of causal dependence-relations provides only probabilistic grounds, however strong the empirical evidence might be.

The asymmetry explains why theoretical knowledge in science remains inherently fallible while logical knowledge achieves certainty. Scientific theories depend ultimately on causal evidence relationships that admit of revision, while logical systems depend on conceptual relationships that are immune to empirical refutation.When I examine how information travels through causal processes, I find that genuine knowledge transmission requires more than mere correlation between events. Information must flow through actual causal channels, not just appear simultaneously at different locations.

Consider a simple case: I see smoke and infer fire. The light waves carrying visual information about the smoke constitute a causal process connecting the fire to my visual system. Without this causal chain, no genuine information transmission occurs.

"To avoid the theoretical arbitrariness associated with such a position, we must say that (#) is true exactly if there is some actual causal process beginning with E and ending with E*." This principle governs all legitimate information transmission.

The causal process requirement explains why mere correlation fails to establish evidential relationships. Two events might be perfectly correlated without either causing the other or sharing a common cause. In such cases, observing one event provides no genuine information about the other.

Causal processes have specific temporal and spatial characteristics. Information cannot travel faster than light or skip intermediate stages without physical mediation. These constraints distinguish genuine causal transmission from spurious correlations.

"Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations." This shows how information processing requires distinguishing between the causal substrate and the informational content it carries.

The substrate must support stable information transmission. Random or chaotic processes cannot reliably carry information from source to destination. The causal process must preserve relevant informational structure while allowing for some degradation or noise.

Multiple causal processes can carry the same information simultaneously. When I hear thunder and see lightning, two different causal processes—sound waves and light waves—transmit information about the same electrical discharge. This redundancy often strengthens evidential support.

But causal processes can also interfere with each other. Background noise, competing signals, or intervening obstacles can disrupt information transmission. Understanding these interference patterns is crucial for evaluating evidential reliability.

The directionality of causal processes determines the direction of information flow. Information travels from cause to effect, not vice versa. This creates temporal asymmetries in evidence relationships that mirror causal asymmetries.

"If a given object's length is given by an irrational number, that object's length cannot be established by measuring that object." This reveals fundamental limits on information transmission through physical measurement processes.

Some information simply cannot be transmitted through any finite causal process. Perfect precision requires infinite information, which no physical system can store or transmit. All actual measurement involves approximation and truncation.

The discrete nature of many physical processes also limits information transmission. Quantum mechanics suggests that information transfer occurs in discrete packets rather than continuous streams. This discreteness affects the precision and reliability of causal information channels.

Causal processes can branch and merge, creating complex information networks. When multiple sources contribute information about the same phenomenon, the resulting evidence must be carefully evaluated for independence and reliability.

Understanding information transmission through causal processes thus provides the foundation for evaluating evidential relationships in both everyday knowledge and scientific investigation.Scientific inference requires distinguishing legitimate from illegitimate rules based on their correspondence to actual dependence-relations in nature. Not every formally valid inference pattern corresponds to genuine causal or logical structures in the world.

"Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations." This illustrates how legitimate inference rules must track real relationships rather than mere formal patterns. The calculator's behavior corresponds to arithmetical operations even though the device itself doesn't perform them.

In scientific contexts, legitimate inference rules must reflect actual causal dependencies between phenomena. When we infer from observable symptoms to underlying causes, the inference is legitimate only if genuine causal relations connect the symptoms to their sources.

"Pro-state lies" often involve illegitimate inference patterns that ignore actual causal structures. Political arguments frequently employ formally valid reasoning that fails to correspond to real-world dependencies, making the inferences scientifically worthless despite their logical form.

Consider medical diagnosis. The inference from fever to infection is legitimate because fever genuinely depends causally on infectious processes in many cases. But inferring from fever to demonic possession employs an illegitimate rule because no such causal dependency exists.

"First of all, laws are not expressed by regularities. A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge." This shows why legitimate scientific inference cannot rely merely on observed regularities. The underlying causal structures determine which inference patterns are scientifically valid.

Illegitimate inference rules often arise from confusing correlation with causation. Statistical associations may support formally valid inferences that lack correspondence to actual causal dependencies. Such inferences are scientifically worthless regardless of their formal validity.

The legitimacy of an inference rule depends on whether it tracks genuine dependence-relations rather than accidental regularities. "A government that permits life-threatening amounts of is not 'small' but simply inadequate." This demonstrates how legitimate inference must connect to real causal relationships between governmental actions and their effects.

Scientific method requires constantly testing whether our inference rules correspond to actual dependencies in nature. Rules that worked in limited contexts may fail when applied more broadly because they don't track universal causal structures.

"The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships." Legitimate inference rules must be grounded in these principled relationships rather than mere surface regularities.

Illegitimate rules often result from overgeneralization. A pattern observed in specific circumstances gets extended beyond its proper domain, where the underlying dependencies no longer hold. Scientific rigor demands recognizing these limitations.

The distinction between legitimate and illegitimate inference rules is not merely formal but depends on empirical facts about causal structures. This makes scientific inference inherently dependent on our understanding of how the world actually works.The approximate and limited scope nature of scientific principles emerges directly from this analysis of inference rules and their dependence on real causal structures. Scientific laws are not perfect concomitances but approximations that hold within restricted domains.

"First of all, laws are not expressed by regularities. A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge." This captures the fundamental limitation of scientific principles - they describe tendencies and dispositions rather than exceptionless regularities.

Every scientific principle operates within implicit boundary conditions. Newton's laws work excellently for medium-sized objects at moderate velocities but break down at quantum scales or relativistic speeds. The principles themselves haven't failed - they were always approximate descriptions valid only within specific domains.

"If a given object's length is given by an irrational number, that object's length cannot be established by measuring that object." This illustrates how measurement itself introduces approximation into our scientific knowledge. Even our most precise instruments cannot capture the full mathematical precision that our theories assume.

Scientific principles must be understood as dispositive rather than deterministic. They tell us what tends to happen under standard conditions, not what must happen in every conceivable circumstance. "Two software-identical units may be physically very different." This shows how even identical formal descriptions can yield different physical outcomes due to contextual factors.

The limited scope of scientific principles reflects the complexity of causal networks in reality. Any scientific law abstracts from countless background conditions that could potentially interfere with its operation. We assume these conditions remain stable, but this assumption always carries risk.

"Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations." Similarly, scientific principles provide useful interpretive frameworks even when they don't perfectly describe underlying mechanisms.

Recognition of approximation and limited scope is not a weakness of science but a strength. It prevents us from applying principles beyond their legitimate domains and encourages continued refinement of our understanding.

"Pro-state lies" often involve treating approximate scientific principles as absolute truths, then using this false precision to justify policies that ignore the principles' actual limitations and scope restrictions.

The self-correcting nature of science depends on acknowledging these limitations. When principles fail in new domains, this signals the need for more fundamental theories rather than ad hoc modifications to preserve existing frameworks.

"It can be interpreted as an attempt to red pill people about the structure of society." Scientific honesty about approximation and scope limitations serves this function by revealing the tentative, contextual nature of our knowledge claims rather than presenting them as dogmatic certainties.The self-modifying nature of knowledge creates fundamental barriers to complete understanding of the world. Every act of knowing changes the knower's conceptual framework, which in turn affects what can be subsequently known and how it can be known.

"In the final analysis, Chomsky and Kant say that, give or take a few nuances, we are born knowing everything we will ever know." This position fails because it ignores how knowledge acquisition transforms our cognitive apparatus. Each new piece of information doesn't simply add to an existing store but reorganizes the entire epistemic structure.

Consider how learning quantum mechanics changes one's understanding of classical physics. The classical concepts don't remain unchanged with quantum additions layered on top. Instead, the entire framework shifts, revealing classical mechanics as a limiting case rather than fundamental truth.

"There is a certainty that can attach to knowledge of what we are consciously thinking that cannot attach to knowledge of the external world." Yet even this introspective knowledge changes as we develop new conceptual vocabularies for describing mental states. The phenomenology itself remains constant, but our propositional knowledge of it evolves.

This self-modification creates recursive complexity. As our knowledge grows, our capacity for knowledge changes, which affects what we can learn next. The knower and the known exist in dynamic interaction rather than static separation.

"If a given object's length is given by an irrational number, that object's length cannot be established by measuring that object." This illustrates a deeper point about knowledge limitations. Some truths exceed our epistemic capacities not accidentally but necessarily.

Complete knowledge would require a knower whose cognitive structure could encompass all possible conceptual frameworks simultaneously. But conceptual frameworks are mutually constraining. Adopting quantum mechanical concepts precludes certain classical ways of thinking about causation and locality.

"Two software-identical units may be physically very different." Similarly, two knowledge states that seem equivalent may have radically different implications for future learning. The path-dependence of knowledge acquisition means that how we arrive at beliefs affects what we can subsequently discover.

The impossibility of complete knowledge isn't merely practical but logical. A complete description of reality would need to include the describing system itself, creating self-referential paradoxes. The map cannot contain itself as a proper part while remaining complete.

"Wittgenstein's Empiricism" suggests that "Creatures in whom there are no 'occult processes' are zombies, and zombies cannot be acculturated." Knowledge requires more than information processing—it demands ongoing transformation of the processing system itself.

This transformation is irreversible. Once we've learned to see the world through quantum mechanical concepts, we cannot return to purely classical thinking. Knowledge burns bridges behind itself, foreclosing certain possibilities while opening others.

The self-modifying nature of knowledge explains why "a genuine 'logic of discovery' is possible and can be revealed by studying AI systems." Artificial systems might exhibit this self-modification more transparently than human cognition, revealing the recursive structures that make complete knowledge impossible.Laws of nature don't guarantee perfect outcomes. I reject the traditional view that natural laws are exceptionless universal statements. "First of all, laws are not expressed by regularities. A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge."

This observation reveals something fundamental about how laws actually work. They're dispositive rather than deterministic—they specify what tends to happen under normal conditions, not what must happen without exception.

Consider gravitational attraction. The law doesn't guarantee that dropped objects will fall. It specifies a disposition that can be overridden by electromagnetic forces, air resistance, or deliberate intervention. "The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships."

The regularities we observe are surface phenomena. The underlying principled relationships are dispositive structures that can be prevented from manifesting by interfering conditions. This explains why scientific laws work so well for prediction while admitting exceptions.

"If a given object's length is given by an irrational number, that object's length cannot be established by measuring that object." Similarly, if laws were perfect universal statements, they couldn't be established by observing finite samples of their instances. The very testability of scientific laws depends on their dispositive rather than exceptionless character.

Traditional philosophy of science assumes laws are universal quantifications: "For all x, if x has property F, then x has property G." But this misrepresents how laws actually function in scientific practice. Laws specify what happens when nothing interferes, not what happens period.

"A government that permits life-threatening amounts of is not 'small' but simply inadequate." The analogy illuminates how dispositive laws work. A law that permitted unlimited exceptions wouldn't be weak—it would be no law at all. But a law that admitted no exceptions couldn't govern a world where multiple forces interact.

The dispositive character of laws explains their scope limitations. Each law applies within specific boundary conditions. Outside those conditions, the law doesn't fail—it simply doesn't apply. This is why "the cognitive operations that mediate vision, language-comprehension, and musical ability are subpersonal."

Psychological laws governing subpersonal processes don't extend to personal-level phenomena. The boundary between levels marks where one set of dispositive laws gives way to another. "Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations."

This suggests that laws at different levels can be simultaneously true without reducing to each other. The dispositive character of laws allows for genuine emergence—higher-level patterns that aren't mere summations of lower-level regularities.

"Incoherence arises from trying to satisfy two incompatible systems." When we try to make laws exceptionless, we force incompatible systematic requirements on nature. Recognizing laws as dispositive resolves this tension by allowing different systems to operate within their proper domains.The recognition that laws are dispositive rather than exceptionless leads directly to a crucial insight: causal relations hold between events, not things. This distinction fundamentally reshapes our understanding of causation itself.

When I say "the match caused the fire," I'm speaking loosely. Strictly speaking, the striking of the match caused the ignition of the combustible material. Events—occurrences, happenings, changes—are the proper relata of causal relations. Things like matches and wood are merely the subjects of these events.

"A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge." This variability makes perfect sense once we recognize that collisions are events, not things. The same physical objects can participate in different types of collision-events, each with different causal powers.

The event-ontology resolves puzzles that plague thing-based theories of causation. If things were the causal relata, we'd expect the same things always to produce the same effects. But a hammer can drive nails, break windows, or sit motionless—depending on what events occur.

"The view that the future is 'fixed' by the present is a defining claim of determinism." But determinism concerns event-sequences, not static thing-arrangements. Present events determine future events through causal necessity. The arrangement of things at a time underdetermines what events will occur.

This event-focus explains why causal laws are dispositive. Events unfold in contexts where multiple causal processes intersect. "Two software-identical units may be physically very different." The same event-type can occur in different physical contexts, producing different downstream effects.

The temporal structure of events also matters crucially. Events have beginnings, middles, and ends. They unfold over time intervals. "To avoid the theoretical arbitrariness associated with such a position, we must say that (#) is true exactly if there is some actual causal process beginning with E and ending with E*."

Causal processes connect event-sequences through time. The process isn't reducible to the discrete events it connects—it's the continuous unfolding that makes causal transmission possible. "If a given object's length is given by an irrational number, that object's length cannot be established by measuring that object."

Just as measurement events can only approximate continuous quantities, causal events can only approximate the continuous processes they instantiate. This approximation character explains why causal laws remain dispositive rather than perfectly exceptionless.

"Supposing that the physical world is deterministic and materialism is right, it's hard to see how there could be free will." But if events, not things, are causally primary, then human actions are events that can have genuine causal efficacy without violating physical determinism.

The event-ontology preserves both causal closure and human agency. Physical events cause other physical events through deterministic processes. But some physical events are also mental events—decisions, choices, intentions. These aren't non-physical interventions but rather physical events described under mental categories.## Program-Causes and Overdetermination in Psychology

Psychology presents special complications for causal analysis because mental events often involve what I call program-causes. These are structural features that predetermine the occurrence of specific determinative events without themselves being events in the ordinary sense.

Consider how a person's goals operate causally. "A person's having a goal does causal work." But the goal isn't simply another event in a causal chain. It's a program-structure that organizes and directs sequences of mental and physical events toward specific outcomes.

When I decide to write this sentence, multiple causal factors converge. My intention to explain program-causes is one factor. My knowledge of philosophical terminology is another. My current emotional state, my caffeine level, even my posture—all contribute causally to the specific words I produce.

This creates apparent overdetermination. The same behavioral outcome seems to have multiple sufficient causes operating simultaneously. Traditional causal analysis struggles with such cases because it assumes each event has a single determining cause.

Program-causes resolve this puzzle. My goal-structure doesn't compete with other causal factors—it coordinates them. The goal is a higher-order organizational principle that channels lower-level causal processes without displacing them.

"Incoherence arises from trying to satisfy two incompatible systems." When someone experiences motivational conflict, competing program-causes attempt to organize the same underlying causal processes in incompatible directions. The resulting behavior reflects whichever program-structure proves more effective at coordinating the available causal resources.

This explains why psychological explanation requires multiple levels of analysis. "The cognitive operations that mediate vision, language-comprehension, and musical ability are subpersonal." These operations follow their own causal patterns, independent of personal-level goals and intentions.

But personal-level program-causes can modulate subpersonal processes. When I focus attention on a particular object, my conscious intention influences which subpersonal visual processing routines become active. The program-cause doesn't override the subpersonal mechanisms—it selects among them.

"AI provides empirically grounded, philosophically illuminating models of scientific reasoning." Artificial intelligence systems demonstrate how program-structures can exhibit genuine causal efficacy. A chess program's strategic goals causally determine which moves it considers, even though the underlying computational processes follow deterministic rules.

The program-structure isn't epiphenomenal. It's a real causal factor that shapes the system's behavior in ways that can't be predicted from knowledge of the lower-level processes alone. "Two software-identical units may be physically very different." The same program can be implemented in different physical substrates while maintaining the same causal powers.

This suggests that psychological program-causes are multiply realizable. The same goal-structure can be implemented in different neural configurations while preserving its causal efficacy. Mental causation doesn't require non-physical intervention—it requires recognizing that some physical structures function as programs that organize other physical processes.

"Creatures in whom there are no 'occult processes' are zombies, and zombies cannot be acculturated." Program-causes aren't occult—they're perfectly physical organizational structures. But they operate according to principles that transcend simple mechanical causation.**Threshold Effects and INUS Conditions**

Most psychological causation involves threshold effects rather than simple linear relationships. "A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge." The same principle applies to mental events. A single thought rarely causes behavior directly—it must combine with other factors to cross critical thresholds.

Consider decision-making. My desire to write this paper doesn't automatically produce writing behavior. It must combine with available time, adequate energy, absence of competing demands, and favorable environmental conditions. Each factor is an INUS condition—insufficient alone but non-redundant within a sufficient complex.

"Incoherence arises from trying to satisfy two incompatible systems." When threshold effects operate, seemingly minor changes can produce dramatic behavioral shifts. A person might maintain stable behavior patterns until multiple stressors accumulate beyond a critical point, then exhibit sudden personality changes.

This explains why psychological prediction is so difficult. "The view that the future is 'fixed' by the present is a defining claim of determinism," but threshold effects make deterministic prediction practically impossible. We can identify necessary conditions without being able to predict when sufficient combinations will occur.

INUS conditions also explain apparent psychological inconsistencies. Someone might be generous in most circumstances but selfish when specific combinations of factors align. The generosity isn't fake—it's real but conditional on threshold requirements being met.

"He describes his own weakness as 'empathy,' and he describes the—" This fragment suggests how even positive traits become problematic under certain threshold conditions. Empathy combined with overwhelming demands might produce paralysis rather than helpful action.

Threshold effects operate at multiple levels simultaneously. Neural firing patterns exhibit thresholds. Cognitive processing has capacity limits. Social situations have tipping points. "If so, that's because, while staving off an n-level change, it permits the occurrence of n+ -level changes."

This creates cascading effects where small changes at one level trigger large changes at higher levels. A minor shift in attention might reorganize entire cognitive processes, leading to completely different behavioral outcomes.

"Veblenian rationality explains luxury consumption, positional goods, and status-seeking." Even economic behavior exhibits threshold effects. Status competition intensifies dramatically once certain wealth thresholds are crossed, producing behaviors that seem irrational from purely economic perspectives.

The INUS structure explains why psychological interventions often fail. Addressing single factors rarely produces lasting change because other necessary conditions remain unmet. Successful therapy typically requires modifying multiple factors simultaneously to cross therapeutic thresholds.

"Pro-state lies" often exploit threshold effects by presenting single factors as sufficient causes. Complex social problems are portrayed as having simple solutions, ignoring the multiple conditions that must align for genuine change.

Understanding threshold effects and INUS conditions is crucial for realistic psychology. Mental causation isn't mechanistic—it's organizational, involving complex interactions among multiple factors that must reach critical combinations before producing observable effects.The threshold analysis reveals fundamental problems with counterfactual theories of causation. These theories claim that C causes E if and only if: had C not occurred, E would not have occurred. This approach fails catastrophically when applied to psychological causation.

Consider causal redundancy in decision-making. I might choose coffee over tea because I prefer coffee's taste. But suppose I also needed caffeine, disliked the tea's temperature, and wanted to appear sophisticated. Each factor alone could have produced the same choice.

The counterfactual test fails here. Even if I hadn't preferred coffee's taste, I still would have chosen coffee due to the other factors. Yet taste preference genuinely contributed to my decision. "To avoid the theoretical arbitrariness associated with such a position, we must say that (#) is true exactly if there is some actual causal process beginning with E and ending with E*."

Psychological causation exhibits systematic redundancy. Multiple motivational systems often converge on identical outcomes through independent pathways. Evolutionary design ensures backup systems for crucial behaviors like mate selection, resource acquisition, and threat avoidance.

"A person's having a goal does causal work" even when other factors would produce the same behavior. The goal's causal efficacy doesn't depend on counterfactual uniqueness. Real causal processes operate regardless of alternative possibilities.

Counterfactual theories also fail with program-causes in psychology. My language acquisition program predetermined that I would learn syntax. But countless environmental factors could have disrupted this process—social isolation, brain injury, sensory deprivation.

The counterfactual analysis suggests the program wasn't causally relevant because alternative scenarios exist where I wouldn't have acquired language. This conclusion is absurd. The program's causal work is evident in the actual developmental process, not in hypothetical alternatives.

"Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations." Similarly, psychological programs perform genuine causal work even when counterfactual conditions might have prevented their operation.

Overdetermination cases further expose counterfactual inadequacy. Suppose both anger and rational calculation lead me to the same decision. Each process alone would have sufficed. Counterfactual analysis incorrectly concludes that neither caused my choice.

But this misses the actual causal structure. Both processes operated simultaneously, each contributing to the outcome through distinct mechanisms. The decision resulted from multiple converging causes, not from neither cause.

"The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships." Counterfactual theories mistake patterns for causal structures.

Real causation involves actual processes, not hypothetical dependencies. When I remember my childhood, specific neural mechanisms retrieve stored information. This process occurs regardless of what might have happened under different circumstances.

The counterfactual approach reduces causation to logical relationships among propositions about possible worlds. But causation is fundamentally about actual processes in the real world, not abstract relationships among hypothetical scenarios.The failure of counterfactual analysis becomes most apparent when we examine causal redundancy systematically. Consider a firing squad where multiple marksmen simultaneously shoot a condemned prisoner. Each bullet alone would prove fatal, yet counterfactual theory absurdly concludes that no individual shot caused death.

This reveals the theory's fundamental confusion between causation and necessity. "To avoid the theoretical arbitrariness associated with such a position, we must say that (#) is true exactly if there is some actual causal process beginning with E and ending with E*." The counterfactual theorist cannot identify any such process because they focus on hypothetical dependencies rather than actual mechanisms.

Causal redundancy pervades psychological phenomena. When I solve a mathematical problem, multiple cognitive processes often converge on the same solution. Pattern recognition, algorithmic computation, and memory retrieval may all contribute simultaneously. Each process performs genuine causal work despite the others' presence.

"Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations." Similarly, redundant psychological causes operate through distinct mechanisms even when their effects overlap. The counterfactual theorist cannot distinguish between these different causal contributions.

Consider artistic creation. Both conscious deliberation and unconscious inspiration may drive the same creative breakthrough. Removing either factor counterfactually might still leave the other sufficient for the outcome. Yet both processes clearly contribute causally to the final result through entirely different mechanisms.

"First of all, laws are not expressed by regularities. A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge." Counterfactual analysis assumes that causal relationships manifest as regular patterns, but actual causation involves specific processes that may produce variable outcomes.

The redundancy problem extends beyond simultaneous overdetermination. Sequential redundancy occurs when multiple backup systems ensure the same result. If my primary alarm fails, my backup alarm wakes me. If that fails, my neighbor's construction noise does. Each represents a genuine causal mechanism despite the others' availability.

"The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships." Counterfactual dependencies are themselves regularities that require explanation, not explanations of causation.

The theory also fails with preemptive causation. Early intervention prevents later causes from operating. A medication cures illness before natural recovery mechanisms activate. The medicine genuinely caused recovery even though natural processes would eventually have succeeded.

Causal redundancy demonstrates that actual causal processes matter more than hypothetical dependencies. Multiple mechanisms can operate simultaneously or sequentially without undermining each other's causal efficacy. The counterfactual approach cannot capture this fundamental feature of real-world causation.

This failure points toward a process-based understanding of causation that focuses on actual mechanisms rather than abstract logical relationships among possible scenarios.Hume's regularity theory offers a radically different approach to causation than the conventional views I've been critiquing. Where counterfactual theories focus on hypothetical dependencies and conventional accounts emphasize necessary connections, Hume reduces causation to observed regularities in experience.

For Hume, causation consists entirely in constant conjunction plus psychological habit. When we repeatedly observe events of type A followed by events of type B, we develop an expectation that future A-events will be followed by B-events. This expectation constitutes our entire concept of causal necessity.

"First of all, laws are not expressed by regularities. A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge." This observation reveals a fundamental problem with Hume's approach. Real causal processes exhibit variability that pure regularity cannot capture.

Hume's theory eliminates mysterious causal powers and necessary connections by reducing them to observable patterns. We never actually perceive causation itself - only temporal succession and spatial contiguity. The feeling of causal necessity arises from psychological habituation, not from any objective feature of the world.

This reductive strategy has considerable appeal. It grounds causal concepts in empirical observation rather than metaphysical speculation. We can verify constant conjunctions through repeated observation, unlike hidden causal powers or counterfactual dependencies.

However, Hume's regularity theory faces severe difficulties when confronted with the complexity of actual causal relationships. Perfect regularities are rare in nature. Most causal processes operate probabilistically or depend on complex background conditions.

The theory also struggles with the direction of causation. Mere temporal priority cannot distinguish genuine causal priority from coincidental sequence. Many regularities involve simultaneous events or backward-looking dependencies that resist Hume's temporal analysis.

More fundamentally, Hume's approach cannot account for the difference between accidental regularities and genuine causal laws. Night follows day with perfect regularity, but day doesn't cause night. Both result from Earth's rotation relative to the sun.

"A government that permits life-threatening amounts of is not 'small' but simply inadequate." This fragment suggests how regularities alone cannot distinguish between different types of systematic relationships. Some patterns reflect causal structures while others represent mere correlations.

Hume's psychological account of causal necessity also faces problems. The feeling of necessity doesn't always correspond to actual regularities. We often feel causal connections in single instances before establishing patterns. Conversely, well-established regularities sometimes feel arbitrary rather than necessary.

The regularity theory succeeds in eliminating metaphysical mysteries but at the cost of eliminating genuine causal relationships. It reduces causation to human psychology rather than objective natural processes.

Despite these limitations, Hume's approach captures important insights about the empirical basis of causal knowledge. We do learn about causal relationships through repeated observation. Our causal concepts do develop through experience rather than pure reason.

The challenge is developing an account that preserves Hume's empirical insights while acknowledging the reality of causal processes beyond mere regularities. This requires recognizing that causation involves actual mechanisms and powers, not just observed patterns.The distinction between transeunt and immanent causation reveals fundamental differences in how causal processes operate. Transeunt causation involves one thing acting upon another distinct thing. Immanent causation involves a thing acting upon itself or its own states.

Most paradigm cases of physical causation are transeunt. A billiard ball strikes another ball, transferring momentum. Fire heats water, causing it to boil. "The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships."

These transeunt processes involve genuine transfer or transmission between distinct entities. The cause and effect are separable in space and time. We can identify the causal agent and the recipient of causal influence.

Immanent causation presents more complex philosophical problems. Consider a person deliberating and then deciding. The same individual is both cause and effect. "A person's having a goal does causal work" - but this work operates within the unified system of that person's psychology.

Mental causation often appears immanent. My beliefs cause my desires, which cause my intentions, which cause my actions. Yet all these states belong to a single psychological system. The causal relationships occur within rather than between distinct substances.

This raises questions about personal identity and psychological unity. If my past self causes my present beliefs, are these transeunt or immanent relations? "Supposing that the physical world is deterministic and materialism is right, it's hard to see how there could be free will." The problem intensifies when we consider whether the person at different times constitutes one continuous agent or multiple temporal stages.

Biological processes complicate the distinction further. A cell divides, creating two cells. Is this immanent causation (one thing affecting itself) or transeunt causation (one thing creating another)? The original cell ceases to exist as such, yet its causal influence continues in its offspring.

Developmental causation presents similar puzzles. An embryo develops into a fetus, then into an infant. Each stage causes the next, but the identity of the developing organism remains continuous. "Two software-identical units may be physically very different." The same biological program can manifest differently while maintaining causal continuity.

Psychological development exhibits comparable patterns. My childhood experiences shape my adult personality. The causal relationship spans decades within a single person's life. Yet the psychological structures involved change dramatically over time.

"The cognitive operations that mediate vision, language-comprehension, and musical ability are subpersonal." These operations involve immanent causation within cognitive systems. Neural processes cause other neural processes within the same brain. The boundaries of the causal system remain unclear.

Program-causes exemplify immanent causation in psychology. A person's goal-structure predetermines specific behavioral responses. The same psychological system contains both the program and its manifestations. "If a given object's length is given by an irrational number, that object's length cannot be established by measuring that object." Similarly, the full causal structure of immanent processes may exceed our analytical capabilities.

The transeunt/immanent distinction connects to broader questions about substance and process. Transeunt causation assumes distinct substances interacting across space. Immanent causation suggests unified processes developing through time.

Both types of causation involve real causal work, not mere regularity. The distinction lies in the unity or separation of causal agents and recipients.My analysis reveals fundamental problems with purely transeunt models of causation. Most psychological phenomena involve both transeunt and immanent elements simultaneously.

Consider learning a language. Environmental stimuli (transeunt causes) trigger internal reorganization of cognitive structures. Yet this reorganization exhibits immanent causation as neural networks modify themselves. "Creatures in whom there are no 'occult processes' are zombies, and zombies cannot be acculturated." The acculturation process requires immanent causal processes within the learner.

"Incoherence arises from trying to satisfy two incompatible systems." This applies directly to causation theory. Attempting to reduce all causation to transeunt relations creates systematic incoherence. Immanent processes resist such reduction.

The temporal dimension complicates both types of causation. Transeunt causation appears instantaneous in idealized models. Real physical interactions unfold over time intervals. "The view that the future is 'fixed' by the present is a defining claim of determinism." Yet causation involves temporal extension, not point-instant determination.

Immanent causation necessarily involves temporal duration. Self-modification requires time for the modification process. A psychological program-cause cannot instantaneously generate all its effects. The causal work occurs through developmental sequences.

"Supposing that the physical world is deterministic and materialism is right, it's hard to see how there could be free will." This difficulty stems partly from conflating transeunt and immanent causation. Free will might involve immanent causal processes that resist external determination.

My position suggests a pluralistic approach to causation. Different domains exhibit different causal structures. Physical collisions exemplify transeunt causation. Biological development exemplifies immanent causation. Psychological processes combine both types.

"This belief of Hempel's is to be understood in terms of his conception of what it is to reduce one discipline to another." Hempel's reductionism assumes transeunt causation dominates all phenomena. This assumption fails for immanent processes in biology and psychology.

The failure of purely transeunt models becomes clear in developmental contexts. "AI provides empirically grounded, philosophically illuminating models of scientific reasoning." Artificial intelligence systems exhibit immanent causation as they modify their own processing structures.

Machine learning algorithms demonstrate immanent causation clearly. The system modifies its own parameters based on experience. No external agent directly causes these modifications. The causal process occurs within the unified system.

"The relation that p bears to phi of p may otherwise be very different from the relation that psi of p bears to p, even though both are consequence relations." Similarly, transeunt and immanent causation involve different types of causal relations despite both being genuinely causal.

This pluralistic framework resolves apparent contradictions in causation theory. We need not force all causal phenomena into a single model. Different causal structures serve different explanatory purposes.

The implications extend beyond metaphysics to scientific methodology. "Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations." We can understand immanent causal processes through appropriate conceptual frameworks without reducing them to transeunt relations.My analysis of causation reveals fundamental limitations in traditional approaches that demand immediate attention. Contemporary philosophy has systematically ignored the distinction between events and processes in causal relationships.

"First of all, laws are not expressed by regularities. A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge." This observation exposes the inadequacy of regularity-based theories of causation. Laws describe dispositive tendencies, not exceptionless regularities.

The failure of regularity theories becomes apparent when we examine threshold effects in complex systems. Multiple factors must converge before causal efficacy emerges. A single match cannot ignite a forest without proper atmospheric conditions, dry vegetation, and wind patterns.

"If so, that's because, while staving off an n-level change, it permits the occurrence of n+ -level changes." Causal systems operate across multiple levels simultaneously. Lower-level constraints enable higher-level phenomena while preventing certain changes at their own level.

This multi-level structure creates what I call program-causes. "A person's having a goal does causal work." Goals function as program-causes by establishing parameters within which specific determinative events unfold. The goal structure predetermines the range of possible outcomes without specifying exact details.

Program-causes operate through what I term INUS conditions - insufficient but non-redundant parts of conditions that are unnecessary but sufficient. Each component contributes essentially to the causal complex while being individually insufficient.

"The view that the future is 'fixed' by the present is a defining claim of determinism." Yet program-causes demonstrate how deterministic systems can exhibit genuine openness. The program fixes the parameters while leaving specific outcomes undetermined.

Consider psychological causation specifically. "The cognitive operations that mediate vision, language-comprehension, and musical ability are subpersonal." These operations involve program-causes operating below conscious awareness. The visual system has goal-directed processes that construct perceptual representations.

"Creatures in whom there are no 'occult processes' are zombies, and zombies cannot be acculturated." This reveals why purely mechanistic accounts of psychology fail. Genuine psychological processes require program-causes that establish meaningful relationships between mental states.

The causal efficacy of mental states creates problems for strict materialism. "Supposing that the physical world is deterministic and materialism is right, it's hard to see how there could be free will." Program-causes provide a solution by showing how deterministic systems can exhibit genuine agency.

"Two software-identical units may be physically very different." This demonstrates that program-causes operate at functional rather than purely physical levels. The same causal structure can be realized through different physical implementations.

Overdetermination frequently occurs in psychological contexts. Multiple program-causes can converge on identical outcomes through independent pathways. "Incoherence arises from trying to satisfy two incompatible systems." When incompatible program-causes operate simultaneously, systematic dysfunction results.

The temporal structure of program-causes differs fundamentally from event-causation. Events occur at specific times and have discrete boundaries. Program-causes operate continuously across extended temporal intervals, maintaining their causal efficacy through persistence rather than occurrence.

This persistence explains why psychological explanations require different conceptual frameworks than physical explanations. "But if individual courses had guaranteed meanings, and if it was always determinate what those meanings were, then passing so much as a single class would be definite proof of a definite kind of merit." Educational processes involve program-causes that operate through extended developmental sequences.## Threshold Effects and INUS Conditions

Causal relationships in complex systems rarely exhibit simple one-to-one correspondences. Most significant effects require the confluence of multiple factors operating simultaneously. I call these threshold effects—discontinuous changes that emerge only when several necessary conditions coincide.

"If so, that's because, while staving off an n-level change, it permits the occurrence of n+ -level changes." This captures how threshold effects operate through hierarchical levels. Lower-level processes can prevent certain changes while enabling higher-level transformations.

INUS conditions provide the proper analysis of such complex causal structures. An INUS condition is an insufficient but non-redundant part of a condition that is unnecessary but sufficient for the effect. Most real-world causation involves INUS conditions rather than simple necessary and sufficient conditions.

Consider psychological development. No single factor determines personality formation. Rather, genetic predispositions, environmental influences, social interactions, and individual choices form complex configurations. Each contributes as an INUS condition within larger sufficient conditions.

"Creatures in whom there are no 'occult processes' are zombies, and zombies cannot be acculturated." This illustrates threshold effects in consciousness. Acculturation requires crossing critical thresholds where multiple cognitive and social capacities converge.

## Problems with Counterfactual Theories of Causation

Counterfactual theories attempt to analyze causation in terms of what would have happened under different circumstances. According to these theories, event C causes event E if and only if: had C not occurred, E would not have occurred.

This analysis fails systematically due to causal redundancy. In most realistic scenarios, multiple alternative causes could produce identical effects. Even if the actual cause had not occurred, some alternative cause would likely have produced the same result.

"To avoid the theoretical arbitrariness associated with such a position, we must say that (#) is true exactly if there is some actual causal process beginning with E and ending with E*." Counterfactual analysis cannot capture actual causal processes because it focuses on hypothetical rather than real connections.

Consider a simple example. A house burns down because someone dropped a lit cigarette. But suppose a faulty electrical wire would have caused the same fire minutes later. The counterfactual "if the cigarette had not been dropped, the house would not have burned" is false, yet the cigarette genuinely caused the fire.

"Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations." This shows how counterfactual analysis confuses levels of description. The calculator's behavior follows mathematical principles without the device understanding mathematics.

## Causal Redundancy and the Failure of Counterfactual Analysis

Causal redundancy pervades natural and social phenomena. Multiple independent causal pathways typically converge on important outcomes. This redundancy serves evolutionary and practical functions but undermines counterfactual theories of causation.

"A government that permits life-threatening amounts of is not 'small' but simply inadequate." Political outcomes result from numerous redundant causes. Electoral results, policy changes, and social movements have multiple sufficient causes operating simultaneously.

The failure of counterfactual analysis reveals deeper problems with our ordinary concept of causation. We cannot analyze causation purely through hypothetical reasoning about alternative possibilities. Actual causal processes must be identified through empirical investigation of real mechanisms.

"If a given object's length is given by an irrational number, that object's length cannot be established by measuring that object." This illustrates the gap between theoretical analysis and empirical reality. Counterfactual theories provide theoretical precision but miss actual causal structures.

Overdetermination represents the most serious challenge to counterfactual analysis. When multiple causes independently guarantee the same effect, counterfactual conditionals become systematically misleading. The effect would have occurred even if any particular cause had been absent.## Hume's Regularity Theory vs. Conventional Views of Causation

I reject both Hume's regularity theory and conventional counterfactual approaches to causation. Both fail to capture the genuine nature of causal relations in the physical world.

"The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships." Hume's mistake was identifying causation with mere regularity. Regularities are surface phenomena that reflect underlying causal structures.

The regularity theory cannot distinguish genuine causal laws from accidental generalizations. "First of all, laws are not expressed by regularities. A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge." Real causal laws operate through mechanisms that may or may not produce observable regularities.

Conventional views of causation fare no better. They typically invoke counterfactual conditionals or probabilistic relationships. These approaches miss the fundamental point that causation involves real connections between events in the physical world.

"To avoid the theoretical arbitrariness associated with such a position, we must say that (#) is true exactly if there is some actual causal process beginning with E and ending with E*." Causation requires actual processes, not hypothetical relationships or statistical correlations.

## Transeunt vs. Immanent Causation

I distinguish between transeunt causation, where causes operate across distinct entities, and immanent causation, where causes operate within unified systems. This distinction clarifies many puzzles about mental causation and personal identity.

Transeunt causation involves genuine causal relations between separate events or objects. "A person's having a goal does causal work" represents transeunt causation when goals influence behavior through psychological mechanisms connecting distinct mental states.

Immanent causation operates within integrated systems where parts influence wholes through internal relationships. "Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations." The calculator's components causally interact to produce computational behavior.

Mental causation typically involves both transeunt and immanent aspects. Goals causally influence actions through transeunt relations between distinct psychological states. But the unified nature of consciousness also involves immanent causation within the integrated mental system.

"The cognitive operations that mediate vision, language-comprehension, and musical ability are subpersonal." These subpersonal processes exhibit immanent causation within the cognitive system while maintaining transeunt causal relations with external stimuli.

This distinction helps resolve debates about mental causation and free will. "Supposing that the physical world is deterministic and materialism is right, it's hard to see how there could be free will." The problem dissolves when we recognize that free will involves immanent causation within the unified agent, not exemption from transeunt causal laws.The resolution of mental causation debates requires understanding how immanent processes operate within deterministic frameworks. "The view that the future is 'fixed' by the present is a defining claim of determinism," yet this fixation operates through both transeunt and immanent causal mechanisms.

Consider how "creatures in whom there are no 'occult processes' are zombies, and zombies cannot be acculturated." Genuine mental causation requires immanent processes that integrate information within conscious systems. These aren't "occult" but represent legitimate causal operations within unified cognitive architectures.

"Two software-identical units may be physically very different." This reveals how immanent causation can produce identical functional outcomes through different physical implementations. The causal work occurs within the system's organizational structure, not merely through transeunt relations between components.

My analysis of scientific inference reveals similar complexities in how knowledge systems operate. "AI provides empirically grounded, philosophically illuminating models of scientific reasoning." These models demonstrate immanent causal processes within information-processing systems that generate new knowledge through internal reorganization.

"A genuine 'logic of discovery' is possible and can be revealed by studying AI systems." Discovery involves immanent causation within knowledge structures, where existing information causally generates new insights through internal logical operations.

The distinction between transeunt and immanent causation illuminates problems with reductionist approaches to interdisciplinary knowledge. "This belief of Hempel's is to be understood in terms of his conception of what it is to reduce one discipline to another." Hempel's reductionism fails because it treats all causation as transeunt, ignoring immanent processes within disciplinary knowledge structures.

"Incoherence arises from trying to satisfy two incompatible systems." This demonstrates how immanent causation within rational systems can produce contradictions when different organizational principles operate simultaneously within the same cognitive framework.

Understanding these causal distinctions requires recognizing that "there is a certainty that can attach to knowledge of what we are consciously thinking that cannot attach to knowledge of the external world." Consciousness involves immanent causal processes that provide direct access to mental states, while external world knowledge depends on transeunt causal chains.

"Different consequence relations" operate through distinct causal mechanisms. "The relation that p bears to phi of p may otherwise be very different from the relation that psi of p bears to p, even though both are consequence relations." Logical consequence involves immanent causation within formal systems, while empirical consequence involves transeunt causation between worldly events.

This framework explains why "if individual courses had guaranteed meanings, and if it was always determinate what those meanings were, then passing so much as a single class would be definite proof of a definite kind of merit." Educational achievement involves immanent causal processes within knowledge systems that cannot be reduced to transeunt behavioral indicators.My analysis of immanent versus transeunt causation reveals fundamental limitations in how we conceptualize knowledge acquisition and rational systems. These causal distinctions expose why complete theoretical unification remains impossible.

"Creatures in whom there are no 'occult processes' are zombies, and zombies cannot be acculturated." This reveals how immanent causal processes within consciousness enable genuine knowledge acquisition, while purely transeunt mechanical processes cannot generate understanding.

The impossibility of complete knowledge stems from the self-modifying nature of rational systems. "In the final analysis, Chomsky and Kant say that, give or take a few nuances, we are born knowing everything we will ever know." This position fails because it ignores how immanent causal processes within developing knowledge structures continuously transform our conceptual frameworks.

"Two software-identical units may be physically very different." This demonstrates how immanent organizational principles operate independently of transeunt physical implementation. Knowledge structures exhibit causal powers that transcend their material substrates.

My framework explains educational and cultural transmission through immanent causal mechanisms. "He describes his own weakness as 'empathy,' and he describes the—" Such psychological processes involve immanent causation within personal value systems that cannot be reduced to external behavioral patterns.

"Veblenian rationality explains luxury consumption, positional goods, and status-seeking." These social phenomena emerge through immanent causal processes within cultural systems, not merely through transeunt economic forces. Status hierarchies exhibit their own internal causal dynamics.

"AI provides empirically grounded, philosophically illuminating models of scientific reasoning." However, artificial systems lack the immanent causal processes that characterize genuine understanding. "Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations."

The distinction between immanent and transeunt causation explains why "a genuine 'logic of discovery' is possible and can be revealed by studying AI systems." Discovery involves immanent causal processes within rational frameworks that generate new knowledge through internal reorganization.

"The cognitive operations that mediate vision, language-comprehension, and musical ability are subpersonal." These processes exhibit immanent causation at levels below conscious awareness, demonstrating how knowledge systems operate through multiple causal strata.

"It can be interpreted as an attempt to red pill people about the structure of society." Social awakening involves immanent causal processes within belief systems that transform understanding through internal rational dynamics rather than external persuasion alone.

My analysis reveals why "pro-state lies" persist through immanent causal mechanisms within ideological systems. These belief structures exhibit self-reinforcing causal patterns that resist external correction.

"A government that permits life-threatening amounts of is not 'small' but simply inadequate." Political evaluation requires understanding how immanent causal processes within institutional structures generate systematic outcomes independent of stated intentions.

The self-modifying nature of knowledge systems means that complete theoretical knowledge remains forever beyond reach. Each advance in understanding transforms the conceptual framework through which further knowledge must be acquired.The impossibility of complete knowledge follows from the self-modifying character of knowledge systems themselves. Each theoretical advance reorganizes the conceptual apparatus through which subsequent inquiry proceeds, creating an endless recursive process that precludes final closure.

"In the final analysis, Chomsky and Kant say that, give or take a few nuances, we are born knowing everything we will ever know." This captures something profound about the structural constraints on knowledge acquisition. The basic logical and causal dependence-relations that make knowledge possible must already be operative in any cognitive system capable of learning.

Yet this doesn't mean knowledge is static. The framework within which we acquire knowledge undergoes continuous modification through the very process of acquiring knowledge. "Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations." Similarly, our cognitive systems implement knowledge-generating processes that transform their own operational principles.

"First of all, laws are not expressed by regularities. A collision may or may not displace an object. It may destroy it. It may not destroy it, but may fail to make it budge." This reveals why scientific knowledge must remain approximate and limited in scope. Natural laws operate as dispositive tendencies rather than exceptionless regularities.

The approximate character of scientific principles reflects deeper facts about the structure of causal dependence-relations in nature. "If so, that's because, while staving off an n-level change, it permits the occurrence of n+ -level changes." Causal systems exhibit hierarchical organization where interventions at one level generate compensatory effects at other levels.

"Two software-identical units may be physically very different." This demonstrates why theoretical knowledge cannot capture the full complexity of concrete causal situations. The same abstract dependence-relations can be realized through radically different physical arrangements.

Scientific laws therefore function as approximate generalizations about dispositive tendencies rather than universal truths. "If a given object's length is given by an irrational number, that object's length cannot be established by measuring that object." Measurement itself introduces systematic limitations on the precision of theoretical knowledge.

The self-modifying nature of knowledge systems creates additional constraints on theoretical completeness. "Incoherence arises from trying to satisfy two incompatible systems." As knowledge advances, previously compatible theoretical commitments may become inconsistent, forcing systematic reorganization of the entire framework.

"There is a certainty that can attach to knowledge of what we are consciously thinking that cannot attach to knowledge of the external world." This asymmetry reflects fundamental differences between immanent and transeunt causal processes. Internal rational operations exhibit a transparency unavailable in external causal relationships.

The impossibility of complete knowledge isn't a practical limitation but a logical necessity. Knowledge systems that could achieve complete self-knowledge would face paradoxes analogous to those confronting perfectly self-referential systems. The very capacity for knowledge requires operational principles that cannot themselves become fully transparent to that system.This asymmetry between internal and external knowledge reveals deeper structural features of causal relationships themselves. Events, not things, enter into genuine causal relations. "A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge." The causal efficacy depends on the specific event-properties, not the substantial nature of the objects involved.

Program-causes represent a distinctive class of causal structures that predetermine the occurrence of specific determinative events. "Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations." The program establishes a framework within which particular causal sequences unfold according to predetermined patterns.

Psychological causation exemplifies program-causation most clearly. "A person's having a goal does causal work." The goal functions as a program-cause that structures subsequent behavioral events without directly determining their specific physical realizations. "Two software-identical units may be physically very different."

Overdetermination frequently occurs in psychological contexts where multiple program-causes operate simultaneously. "Supposing that the physical world is deterministic and materialism is right, it's hard to see how there could be free will." The apparent conflict dissolves when we recognize that program-causation operates at different levels of description than physical determinism.

Threshold effects introduce discontinuous changes requiring the confluence of multiple factors. These effects cannot be captured by simple linear causal models. "If so, that's because, while staving off an n-level change, it permits the occurrence of n+ -level changes." The causal structure exhibits hierarchical organization where changes at different levels follow distinct principles.

INUS conditions provide a more adequate framework for understanding complex causal relationships. An INUS condition is an insufficient but non-redundant part of a condition that is unnecessary but sufficient for the effect. Most real causal relationships involve INUS conditions rather than simple sufficient or necessary conditions.

"Pro-state lies" illustrate how causal analysis applies to social phenomena. "A government that permits life-threatening amounts of is not 'small' but simply inadequate." The causal relationship between governmental structures and social outcomes involves complex threshold effects and program-causation rather than simple mechanical relationships.

Counterfactual theories of causation fail precisely because they cannot handle causal redundancy adequately. "To avoid the theoretical arbitrariness associated with such a position, we must say that (#) is true exactly if there is some actual causal process beginning with E and ending with E*." The existence of alternative causal pathways undermines counterfactual analysis.

Consider cases where multiple independent causal chains could produce the same effect. Even if we eliminate one potential cause, the effect might still occur through alternative pathways. The counterfactual "if the cause had not occurred, the effect would not have occurred" becomes false even when genuine causation exists.Causal redundancy presents the decisive objection to counterfactual theories. When multiple independent causal processes can produce identical effects, the counterfactual test fails systematically. The effect would occur even if we removed any single cause, yet each cause remains genuinely causal.

This failure reveals the deeper problem with counterfactual approaches. "The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships." Counterfactuals focus on regularities rather than the underlying causal structures that generate them.

Hume's regularity theory provides a more defensible foundation for understanding causation. Rather than invoking mysterious necessary connections or counterfactual dependencies, we can ground causation in observed patterns of succession and contiguity. This approach avoids the metaphysical commitments that plague other theories.

However, conventional views of causation contain important insights that pure regularity theory cannot capture. The distinction between genuine causal laws and mere coincidental regularities requires something beyond simple pattern recognition. We need criteria for distinguishing lawlike from accidental generalizations.

The solution involves recognizing that causal relations fundamentally concern events rather than things. "First of all, laws are not expressed by regularities. A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge." Events enter into causal relations through their properties and the circumstances of their occurrence.

This event-based approach resolves many puzzles about causal asymmetry and temporal direction. Events have intrinsic temporal orientations that things lack. When we say that one event causes another, we refer to a relationship between temporally ordered occurrences, not between static objects.

The distinction between transeunt and immanent causation becomes crucial here. Transeunt causation involves one event bringing about changes in distinct objects or systems. Immanent causation involves changes within a single system or substance. Most scientific causation is transeunt, involving interactions between separate events or processes.

"Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations." This illustrates how we can maintain causal realism while recognizing the interpretive dimension of causal attribution. Physical processes exhibit patterns that we legitimately describe in causal terms without requiring mysterious causal powers.

The key insight is that causation involves both objective patterns in nature and our conceptual frameworks for interpreting those patterns. Neither pure objectivism nor pure conventionalism captures the full picture. Causal relationships exist in the world, but our understanding of them depends on the conceptual resources we bring to their analysis.

This perspective allows us to maintain scientific realism while acknowledging the limitations of our causal knowledge. "If a given object's length is given by an irrational number, that object's length cannot be established by measuring that object." Similarly, complete causal knowledge remains forever beyond our reach, but partial understanding remains both possible and valuable.The relationship between events and causation reveals fundamental constraints on knowledge acquisition. Events possess temporal boundaries and specific characteristics that make them suitable relata for causal connections. Things, by contrast, persist through time and undergo changes without themselves being the proper subjects of causal relations.

"The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships." This captures my view that observable patterns point toward underlying causal structures rather than exhausting them.

Program-causes represent a special category requiring careful analysis. These are structures that predetermine the occurrence of specific determinative events. A computer program exemplifies this: the code structure ensures that certain computational events will occur given appropriate inputs. The program doesn't cause individual computational steps in the ordinary sense but creates conditions under which those steps must occur.

Overdetermination in psychological contexts presents particular complexities. Multiple program-causes can simultaneously guarantee the same behavioral outcome. A person's decision might result from both rational deliberation and unconscious emotional programming. Neither alone determines the outcome, yet either might suffice.

"A person's having a goal does causal work." Goals function as program-causes, establishing frameworks within which specific actions become inevitable given certain triggering conditions. The goal doesn't directly cause individual behaviors but creates dispositional structures that channel behavior in predictable directions.

Threshold effects complicate simple causal analysis. Many phenomena require the confluence of multiple factors reaching critical levels simultaneously. Water boils only when sufficient heat combines with appropriate pressure conditions. Neither factor alone suffices, yet their combination produces discontinuous change.

INUS conditions—insufficient but non-redundant parts of conditions that are unnecessary but sufficient—capture this complexity. A spark is an INUS condition for fire: insufficient alone, but non-redundant within a sufficient condition that includes oxygen and combustible material. The condition itself (spark plus oxygen plus fuel) is unnecessary since other sufficient conditions exist.

"First of all, laws are not expressed by regularities. A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge." This emphasizes that causal laws describe dispositions rather than exceptionless regularities. The law governs what happens under standard conditions while allowing for interference and threshold effects.

Counterfactual theories of causation fail precisely because they cannot handle such complexity. These theories claim that C causes E if and only if E would not have occurred without C. But causal redundancy makes this analysis inadequate.

"To avoid the theoretical arbitrariness associated with such a position, we must say that (#) is true exactly if there is some actual causal process beginning with E and ending with E*." Actual causal processes, not hypothetical counterfactual scenarios, determine causal relationships.

Consider assassination attempts with multiple shooters. If both bullets would prove fatal, neither shooter's action satisfies the counterfactual condition—the victim would die regardless. Yet both actions are genuinely causal. The counterfactual analysis fails because it ignores the actual causal processes involved.

Causal redundancy pervades natural phenomena. Multiple pathways often lead to identical outcomes. Evolution produces similar solutions through different developmental routes. Neural networks achieve identical computational results through alternative connection patterns.

Hume's regularity theory fares better than counterfactual approaches but remains incomplete. Hume correctly emphasized observable regularities as evidence for causal connections. But regularities alone cannot distinguish genuine causal laws from accidental generalizations.The distinction between transeunt and immanent causation reveals deeper problems with conventional causal analysis. Transeunt causation involves one distinct entity acting upon another—billiard balls colliding, magnets attracting iron filings. Immanent causation involves internal changes within a single entity—an organism growing, a mind forming beliefs.

"The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships." This captures why Hume's regularity theory, though superior to counterfactual approaches, cannot be the complete story.

Regularities provide evidence for underlying causal structures but don't constitute those structures themselves. The regularity that fire produces smoke reflects deeper facts about combustion processes, not mere constant conjunction. We observe patterns because genuine dependence-relations hold in nature.

"First of all, laws are not expressed by regularities. A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge." This illustrates why causal laws cannot be reduced to exceptionless generalizations. Real causation operates through complex mechanisms that produce variable outcomes depending on background conditions.

Program-causes introduce another layer of complexity ignored by standard theories. These are structures that predetermine the occurrence of specific determinative events. Genetic programs cause developmental sequences. Computational programs cause calculation steps. Social institutions cause behavioral patterns.

"Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations." The calculator's program-cause structure makes arithmetical descriptions appropriate even though the physical processes involve only electronic state changes.

Program-causes operate through immanent causation rather than transeunt causation. The program doesn't push events from outside but provides internal organizational principles that shape how events unfold. This creates causal relationships that resist analysis in terms of discrete event-to-event connections.

Overdetermination compounds these difficulties. Multiple program-causes often operate simultaneously within complex systems. Psychological behavior results from genetic, developmental, social, and cognitive programs working in parallel. No single program provides complete causal explanation.

"A person's having a goal does causal work." Goals function as program-causes that organize sequences of actions toward specific outcomes. But goal-directed behavior typically involves multiple overlapping programs—biological drives, learned habits, social expectations, conscious intentions.

The confluence of multiple program-causes creates threshold effects where small changes produce dramatic discontinuities. Psychological breakdown occurs when conflicting programs exceed the system's integrative capacity. Social revolutions emerge when institutional programs lose coordination.

These complex causal structures explain why scientific knowledge must remain approximate and limited in scope. Perfect prediction would require complete knowledge of all relevant program-causes and their interactions—an impossible epistemic achievement.

"If a given object's length is given by an irrational number, that object's length cannot be established by measuring that object." This mathematical limitation parallels the causal complexity that makes complete scientific knowledge unattainable. Some aspects of reality exceed our representational capabilities.INUS conditions provide a more precise framework for understanding these complex causal relationships. An INUS condition is an insufficient but non-redundant part of a condition that is unnecessary but sufficient for the effect. Most real-world causation involves INUS conditions rather than simple sufficient causes.

Consider psychological causation. Childhood trauma may be an INUS condition for later depression—insufficient by itself, non-redundant within the causal complex, part of an unnecessary but sufficient condition that includes genetic predisposition, current stressors, and social isolation.

"The view that the future is 'fixed' by the present is a defining claim of determinism." But deterministic systems can still exhibit INUS causation. Even if the future is fixed, our knowledge remains limited to identifying partial causal factors rather than complete determining conditions.

This analysis reveals fundamental problems with counterfactual theories of causation. Counterfactual approaches claim that C causes E if and only if: had C not occurred, E would not have occurred. But this analysis fails systematically due to causal redundancy.

"To avoid the theoretical arbitrariness associated with such a position, we must say that (#) is true exactly if there is some actual causal process beginning with E and ending with E*." Counterfactuals cannot capture the reality of actual causal processes because they focus on hypothetical scenarios rather than real mechanisms.

Causal redundancy creates decisive counterexamples to counterfactual analysis. Suppose a prisoner faces two executioners who fire simultaneously. Each shot would have killed the prisoner independently. The counterfactual "if executioner A had not fired, the prisoner would still have died" is true, yet executioner A's shot genuinely caused the death.

"Two software-identical units may be physically very different." This observation applies directly to causal redundancy. Multiple physically distinct processes can produce identical effects through different causal pathways. Counterfactual analysis cannot distinguish between genuine causes and redundant alternatives.

Similar problems arise with overdetermination. When multiple sufficient causes operate simultaneously, counterfactual tests yield incorrect results. Each cause satisfies the counterfactual condition—remove any one and the effect still occurs—yet each genuinely contributes to the outcome.

"First of all, laws are not expressed by regularities. A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge." This observation undermines both counterfactual and regularity theories of causation.

The failure of counterfactual analysis points toward a more fundamental issue: causation involves actual processes and mechanisms, not hypothetical dependencies. Real causal relationships exist independently of our ability to construct accurate counterfactual conditionals about them.Consider threshold effects in psychological causation. Multiple factors must converge before producing observable behavioral changes. No single factor satisfies counterfactual conditions, yet each contributes essentially to the causal process.

"A person's having a goal does causal work" demonstrates how psychological states enter genuine causal relations. Goals function as program-causes, creating structured dispositions that predetermine specific responses to environmental triggers.

Program-causes operate differently from simple event causation. They establish ongoing causal potentials rather than discrete causal episodes. A goal remains causally active across extended temporal intervals, shaping multiple behavioral outcomes through its dispositional structure.

"The cognitive operations that mediate vision, language-comprehension, and musical ability are subpersonal" reveals another layer of causal complexity. Subpersonal processes constitute genuine causes of conscious experience, yet they operate below the threshold of introspective awareness.

These subpersonal mechanisms exemplify INUS conditions—insufficient but non-redundant parts of sufficient conditions. Each cognitive operation contributes necessarily to the total causal complex producing conscious awareness, though none alone suffices.

Overdetermination appears frequently in psychological causation. Multiple belief-desire pairs can independently motivate identical actions. Traditional causal analysis struggles with such cases because removing any single motivational factor leaves alternative sufficient conditions intact.

"Incoherence arises from trying to satisfy two incompatible systems" illustrates how conflicting program-causes create psychological tension. Each system operates according to its own causal logic, generating incompatible behavioral tendencies.

The materialist framework faces particular difficulties with program-causes. Physical determinism suggests that current brain states fully determine future behavior. Yet program-causes seem to introduce additional causal powers that transcend mere physical necessity.

"Supposing that the physical world is deterministic and materialism is right, it's hard to see how there could be free will" captures this tension precisely. Program-causes require causal efficacy that appears inconsistent with strict physical determinism.

Consider how goals modify causal relationships. Without goals, environmental stimuli produce responses according to simple stimulus-response patterns. Goals introduce selective attention and strategic planning that fundamentally alter these causal pathways.

"The view that the future is 'fixed' by the present is a defining claim of determinism" seems to conflict with goal-directed behavior. Goals appear to make the future depend on abstract representations rather than current physical states alone.

This creates what I call the program-cause paradox. Goals must be physically realized to have causal power, yet their causal efficacy seems to depend on their representational content rather than their physical properties.

The solution requires recognizing that program-causes operate through physical mechanisms while maintaining genuine causal autonomy. Physical realization enables causal power without reducing causal relationships to purely physical interactions.

"Creatures in whom there are no 'occult processes' are zombies, and zombies cannot be acculturated" suggests that genuine psychological causation requires more than mechanical physical processes. Program-causes introduce the kind of structured causal organization that distinguishes minded beings from mere physical systems.## Threshold Effects and Complex Causation

Program-causes rarely operate in isolation. Most psychological phenomena involve threshold effects requiring multiple causal factors to converge simultaneously. "Incoherence arises from trying to satisfy two incompatible systems" illustrates how competing program-causes create discontinuous behavioral changes.

Consider decision-making under conflicting goals. Below certain threshold values, competing motivations produce stable behavioral patterns. Above these thresholds, small changes trigger dramatic behavioral shifts.

"He describes his own weakness as 'empathy,' and he describes the" - this fragment points toward how emotional program-causes interact with rational ones. Empathy operates as a threshold-sensitive program-cause that can override deliberative reasoning when emotional intensity exceeds critical values.

These threshold effects reveal why simple regularity theories fail for psychological phenomena. "The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships."

## INUS Conditions in Mental Causation

Most psychological events involve INUS conditions - insufficient but non-redundant parts of conditions that are unnecessary but sufficient. A person's anger might be an INUS condition for aggressive behavior, neither necessary nor sufficient alone but causally relevant within specific causal complexes.

"A person's having a goal does causal work" through INUS relationships. Goals combine with beliefs, emotions, and situational factors to produce behavior. No single factor is necessary or sufficient, yet each contributes genuine causal power.

Consider how beliefs function as INUS conditions. False beliefs can produce successful actions when combined with compensating factors. True beliefs can produce failures when other causal factors are absent or counteractive.

"Veblenian rationality explains luxury consumption, positional goods, and status-seeking" through INUS mechanisms. Status goals combine with economic resources, social positioning, and cultural knowledge to produce consumption patterns inexplicable through simple utility maximization.

## Problems with Counterfactual Analysis

Traditional counterfactual theories claim that C causes E if and only if: had C not occurred, E would not have occurred. This analysis fails systematically for psychological phenomena due to causal redundancy.

"To avoid the theoretical arbitrariness associated with such a position, we must say that (#) is true exactly if there is some actual causal process beginning with E and ending with E*." Counterfactual analysis ignores actual causal processes in favor of hypothetical scenarios.

Consider memory retrieval. Multiple neural pathways can access the same information. Even if one pathway were blocked, others could produce identical recall. Counterfactual analysis would deny causal efficacy to functioning pathways simply because alternatives exist.

"If so, that's because, while staving off an n-level change, it permits the occurrence of n+ -level changes" captures how causal redundancy operates across different organizational levels. Higher-level psychological processes maintain stability despite lower-level variations through multiple realizability.

## Causal Redundancy in Psychology

Psychological systems exhibit extensive causal redundancy. Multiple cognitive mechanisms can produce identical behavioral outputs through different causal pathways. This redundancy serves adaptive functions but creates problems for causal analysis.

"Two software-identical units may be physically very different" illustrates how functional redundancy operates. Different neural implementations can support identical psychological functions, making counterfactual analysis inappropriate for mental causation.

Emotional responses exemplify causal redundancy. Fear can result from direct threat perception, learned associations, cognitive appraisal, or physiological arousal. Blocking any single pathway rarely eliminates fear responses due to compensatory mechanisms.

This redundancy explains why psychological interventions often require multiple approaches. "Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations" - similarly, minds require functional rather than purely mechanical analysis.## Program-Causes and Psychological Determination

I distinguish program-causes from ordinary causal events. A program-cause establishes structural conditions that predetermine specific outcomes without directly producing them. Genetic programs, learned behavioral patterns, and cognitive schemas function as program-causes in psychology.

"A person's having a goal does causal work" - but goals operate as program-causes rather than efficient causes. Goals establish parameters within which specific actions emerge, creating structured possibility spaces for behavior.

Developmental programs illustrate this clearly. Genetic instructions don't directly cause specific neural connections but establish constraints that channel development toward particular outcomes. Environmental inputs trigger predetermined developmental sequences.

"The cognitive operations that mediate vision, language-comprehension, and musical ability are subpersonal" - these operations function as program-causes for conscious experience. They create the structural conditions necessary for awareness without directly producing conscious content.

## Overdetermination in Mental Causation

Psychological events frequently exhibit overdetermination. Multiple sufficient causes operate simultaneously, any one of which could produce the observed effect. This creates analytical challenges for identifying genuine causal relationships.

Belief formation demonstrates overdetermination clearly. A single belief might result from perceptual evidence, social testimony, logical inference, or emotional motivation. Each pathway provides sufficient grounds for the belief.

"Creatures in whom there are no 'occult processes' are zombies, and zombies cannot be acculturated" - genuine psychological causation requires more than behavioral regularities. Mental states must involve real causal processes, not mere functional mappings.

This overdetermination explains why psychological explanations resist simple causal models. "Incoherence arises from trying to satisfy two incompatible systems" - attempting to reduce mental causation to simple mechanical processes creates theoretical contradictions.

## Threshold Effects in Cognition

Many psychological phenomena exhibit threshold effects where gradual changes suddenly produce discontinuous results. These effects require confluence of multiple causal factors rather than simple linear causation.

Decision-making exemplifies threshold effects. Accumulated evidence, emotional pressure, and situational factors combine until reaching a critical point where action suddenly occurs. No single factor determines the timing.

"But if individual courses had guaranteed meanings, and if it was always determinate what those meanings were, then passing so much as a single class would be definite proof of a definite kind of merit" - but educational outcomes depend on threshold effects where multiple factors must align for genuine learning.

Memory retrieval shows similar patterns. Contextual cues, emotional states, and associative networks must reach sufficient activation levels before memories become accessible. Gradual increases in retrieval strength suddenly produce conscious recollection.

## INUS Conditions in Psychology

Psychological causation frequently involves INUS conditions - factors that are insufficient but non-redundant parts of conditions that are unnecessary but sufficient for their effects.

Traumatic stress responses illustrate INUS conditions clearly. Individual vulnerability, stressor severity, social support, and coping resources each constitute INUS conditions for psychological trauma. None alone determines outcomes.

"AI provides empirically grounded, philosophically illuminating models of scientific reasoning" - artificial systems help identify INUS conditions in cognition by isolating specific computational requirements for intelligent behavior.

Therapeutic interventions target INUS conditions rather than necessary causes. Changing thought patterns, improving social relationships, or developing coping skills can each contribute to recovery without being individually sufficient.## Problems with Counterfactual Theories of Causation

The counterfactual analysis of causation faces decisive objections from psychological phenomena. Consider depression onset: multiple causal pathways can produce identical symptoms through entirely different mechanisms.

"If a given object's length is given by an irrational number, that object's length cannot be established by measuring that object." Similarly, if multiple sufficient conditions exist for depression, counterfactual analysis breaks down completely.

Suppose genetic predisposition, chronic stress, and social isolation each constitute sufficient conditions for major depression in particular individuals. The counterfactual theorist claims: "If genetic predisposition hadn't occurred, depression wouldn't have followed."

But this counterfactual is false when alternative sufficient conditions remain present. Chronic stress alone might have produced identical depressive episodes. The counterfactual analysis incorrectly denies genuine causal relationships.

"Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations" - psychological causation operates through multiple realizability that defeats counterfactual analysis.

## Causal Redundancy and the Failure of Counterfactual Analysis

Causal redundancy pervades psychological explanation. Anxiety disorders develop through genetic vulnerability, learned helplessness, cognitive distortions, or neurochemical imbalances - often simultaneously.

"To avoid the theoretical arbitrariness associated with such a position, we must say that (#) is true exactly if there is some actual causal process beginning with E and ending with E*." Actual causal processes matter more than counterfactual dependencies.

Consider phobia acquisition. Classical conditioning, observational learning, and cognitive misappraisal can each produce identical phobic responses. Counterfactual analysis fails because eliminating any single pathway leaves others intact.

The redundancy extends beyond psychology. "A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge." Physical causation itself exhibits the redundancy that defeats counterfactual theories.

"Two software-identical units may be physically very different" - multiple physical realizations of identical causal structures demonstrate that counterfactual dependencies cannot capture genuine causal relationships.

## Hume's Regularity Theory vs. Conventional Views of Causation

Hume's regularity theory provides superior analysis of psychological causation despite conventional objections. Regular conjunctions between mental states and behaviors constitute the empirical foundation for causal knowledge.

"The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships."

I reject this conventional view. Regularities constitute rather than merely express causal relationships in psychology. Observed patterns of stimulus-response connections, learning curves, and behavioral modifications provide direct evidence of causal structures.

"First of all, laws are not expressed by regularities. A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge." This apparent irregularity actually supports Hume's position.

Psychological laws exhibit similar apparent exceptions. Reinforcement schedules don't invariably produce predicted response patterns. Individual differences, contextual factors, and competing motivations create apparent violations.

But these exceptions reflect incomplete specification of relevant conditions rather than failures of regularity theory. "Laws of nature as dispositive rather than exceptionless" - psychological regularities operate within specific boundary conditions that must be empirically determined.**Transeunt vs. Immanent Causation in Psychological Systems**

Psychological causation involves both transeunt and immanent processes requiring distinct analytical approaches. Transeunt causation operates between separate psychological systems - one person influencing another's beliefs or behaviors through communication or modeling.

"A person's having a goal does causal work" exemplifies transeunt psychological causation. Goals function as discrete causal agents producing effects in behavioral systems external to the goal-formation process itself.

Immanent causation operates within unified psychological systems. Memory consolidation, attention allocation, and emotional regulation involve causal processes where the system acts upon itself rather than external targets.

"Creatures in whom there are no 'occult processes' are zombies, and zombies cannot be acculturated." This highlights the necessity of immanent causal processes for genuine psychological functioning. Acculturation requires internal causal mechanisms that modify behavioral dispositions through experience.

**Program-Causes and Psychological Architecture**

Program-causes operate extensively in psychological systems through learned behavioral patterns and cognitive schemas. "The cognitive operations that mediate vision, language-comprehension, and musical ability are subpersonal" - these operations function as program-causes determining specific behavioral outcomes.

Habit formation exemplifies program-causation in psychology. Repeated behavioral sequences create neural structures that predetermine future responses to similar stimulus conditions. The program-cause (established habit pattern) generates specific behaviors without requiring conscious deliberation.

"Two software-identical units may be physically very different." This principle applies directly to psychological program-causes. Identical behavioral programs can be implemented through different neural substrates while producing functionally equivalent outcomes.

Educational systems exploit program-causation through curriculum design. "But if individual courses had guaranteed meanings, and if it was always determinate what those meanings were, then passing so much as a single class would be definite proof of a definite kind of merit." The indeterminacy of educational meanings reflects the complex interaction between program-causes and individual psychological systems.

**Overdetermination in Psychological Explanation**

Psychological phenomena frequently exhibit causal overdetermination requiring careful analytical distinction between genuine and apparent cases. Multiple motivational systems, competing goals, and parallel processing mechanisms create situations where several causal pathways could produce identical behavioral outcomes.

"Incoherence arises from trying to satisfy two incompatible systems." This describes genuine overdetermination in psychological conflict situations. Approach-avoidance conflicts involve competing causal systems each sufficient to determine behavior in opposite directions.

Apparent overdetermination occurs when multiple psychological factors correlate with behavioral outcomes without each being individually sufficient. Statistical correlation doesn't establish genuine causal overdetermination - only controlled experimental manipulation can distinguish between genuine multiple causation and spurious correlation.

"Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations." Similarly, psychological systems may exhibit behavioral patterns interpretable through multiple theoretical frameworks without genuine causal overdetermination occurring.

The resolution requires identifying which causal pathway actually operates in specific instances rather than assuming all correlated factors contribute causally.**Threshold Effects in Psychological Causation**

Psychological phenomena often require confluence of multiple factors reaching critical thresholds before producing observable effects. Unlike simple linear causation, psychological threshold effects create discontinuous behavioral changes when combined causal factors exceed specific activation levels.

"A government that permits life-threatening amounts of is not 'small' but simply inadequate." This illustrates how threshold effects operate - multiple inadequate factors combine to produce qualitatively different outcomes when critical levels are reached.

Depression exemplifies psychological threshold effects. Multiple risk factors - genetic predisposition, environmental stressors, cognitive patterns, social isolation - individually insufficient to produce clinical depression. Only when their combined impact exceeds critical thresholds do depressive episodes emerge.

Learning demonstrates similar threshold dynamics. Repeated exposure to information creates gradual neural changes until sudden comprehension occurs when accumulated changes reach cognitive thresholds.

**INUS Conditions in Psychological Explanation**

Psychological causation frequently involves INUS conditions - factors that are insufficient but non-redundant parts of conditions that are unnecessary but sufficient for specific outcomes.

"Two software-identical units may be physically very different." This captures how identical psychological outcomes can result from different causal configurations involving distinct INUS conditions.

Phobia development illustrates INUS causation. Traumatic experience alone insufficient for phobia formation. Genetic anxiety predisposition alone insufficient. Specific environmental triggers alone insufficient. However, traumatic experience combined with genetic predisposition and specific environmental context creates sufficient condition for phobia development.

Each component represents an INUS condition - individually insufficient but non-redundant within the sufficient causal complex. Alternative causal complexes involving different INUS conditions could produce identical phobic outcomes.

**Problems with Counterfactual Analysis of Psychological Causation**

Counterfactual theories of causation fail particularly dramatically in psychological contexts due to pervasive causal redundancy and multiple realizability of mental states.

"If so, that's because, while staving off an n-level change, it permits the occurrence of n+ -level changes." Psychological systems exhibit complex hierarchical causation where preventing one causal pathway activates alternative pathways producing identical outcomes.

Consider decision-making processes. Counterfactual analysis suggests that if specific reasoning processes hadn't occurred, different decisions would result. But psychological redundancy means alternative reasoning pathways, unconscious processes, or emotional systems could produce identical decisions through completely different causal mechanisms.

Memory formation demonstrates similar counterfactual failures. If specific encoding processes were absent, memories might still form through alternative neural pathways, emotional consolidation, or implicit learning mechanisms.

**Causal Redundancy in Psychological Systems**

Psychological systems exhibit extensive causal redundancy where multiple independent causal pathways can produce identical behavioral and mental outcomes.

"The relation that p bears to phi of p may otherwise be very different from the relation that psi of p bears to p, even though both are consequence relations." Different psychological processes can establish identical mental contents through entirely different causal mechanisms.

Emotion regulation exemplifies causal redundancy. Cognitive reappraisal, behavioral modification, pharmaceutical intervention, meditation, social support, and environmental changes can each independently produce identical emotional outcomes through distinct causal pathways.

This redundancy invalidates counterfactual analysis because removing any single causal factor doesn't prevent the outcome - alternative pathways remain available.**Hume's Regularity Theory vs. Conventional Views of Causation**

My analysis of causal redundancy brings us to fundamental questions about the nature of causation itself. The failure of counterfactual theories forces reconsideration of competing approaches to understanding causal relationships.

Hume's regularity theory holds that causation consists entirely in constant conjunctions between types of events. On this view, saying that fire causes smoke means nothing more than that events of type "fire" are regularly followed by events of type "smoke."

"The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships." This captures my fundamental disagreement with pure regularity theories.

Conventional views of causation posit genuine causal powers, necessary connections, or productive relationships that go beyond mere regularity. These approaches attempt to ground causation in metaphysical features of reality rather than reducing it to observed patterns.

**The Inadequacy of Pure Regularity**

Pure regularity theory faces decisive objections that reveal its inadequacy as a complete account of causation.

"First of all, laws are not expressed by regularities. A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge." This observation demonstrates that even paradigmatic causal relationships don't exhibit perfect regularity.

Physical interactions produce variable outcomes depending on countless contextual factors. The same collision force applied to different objects, or to the same object under different conditions, generates different results.

Psychological causation exhibits even greater irregularity. The same stimulus can produce different responses across individuals, developmental stages, or situational contexts. Yet we correctly identify genuine causal relationships despite this variability.

**Beyond Simple Regularity**

My position acknowledges that while regularities provide evidence for causal relationships, they neither constitute nor fully capture the nature of causation.

"Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations." This analogy illuminates how causal relationships can be real and explanatorily valuable even when the underlying mechanisms differ from surface regularities.

Causal relationships involve principled connections that manifest through regularities under standard conditions, but the connections themselves transcend mere correlation patterns.

**Transeunt vs. Immanent Causation**

The distinction between transeunt and immanent causation provides crucial insight into different types of causal relationships operating in psychological and physical domains.

Transeunt causation involves causal influence passing from one distinct entity to another. Physical collisions, electromagnetic forces, and interpersonal influences exemplify transeunt causal relationships.

Immanent causation occurs when an entity's properties or states causally determine its own subsequent properties or states. Psychological processes like belief revision, emotional regulation, and skill development often involve immanent causation.

"A person's having a goal does causal work" - this exemplifies immanent causation where psychological states within an individual generate causal effects on that same individual's behavior and mental processes.

Understanding this distinction helps resolve apparent paradoxes in psychological explanation where the same entity appears to be both cause and effect in causal relationships.**Theoretical Knowledge as Necessarily Inferential**

Theoretical knowledge differs fundamentally from direct observational knowledge in requiring inferential connections to unobservable structures and processes. "AI provides empirically grounded, philosophically illuminating models of scientific reasoning" - this captures how theoretical frameworks necessarily involve inference from observable phenomena to underlying explanatory mechanisms.

I cannot directly observe electrons, gravitational fields, or psychological processes like memory consolidation. My knowledge of these theoretical entities emerges through inferential reasoning from observable effects to their unobservable causes.

"The cognitive operations that mediate vision, language-comprehension, and musical ability are subpersonal" - this illustrates how theoretical knowledge penetrates beyond conscious awareness to explanatory structures that cannot be directly accessed through introspection or observation.

**Standard Conditions for Knowledge: Belief, Truth, and Justification**

Knowledge requires three standard conditions: belief in a proposition, truth of that proposition, and adequate justification for the belief. These conditions interact through the dependence-relations I have analyzed.

"There is a certainty that can attach to knowledge of what we are consciously thinking that cannot attach to knowledge of the external world" - this highlights how justification conditions vary across different domains of knowledge.

Direct knowledge of my own conscious states requires minimal inferential justification. Knowledge of external world phenomena requires complex chains of causal and logical dependence-relations connecting sensory evidence to theoretical conclusions.

The justification condition proves most problematic because it demands correspondence between inference rules and genuine dependence-relations in reality.

**Causal vs. Logical Necessity and Evidence Relationships**

Causal necessity operates through physical processes and natural regularities. Logical necessity operates through conceptual relationships and formal structures. Evidence relationships connect these two domains.

"The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships" - regularities provide evidence for underlying causal necessities without constituting those necessities themselves.

Logical necessity governs inference rules and conceptual analysis. "Given any open-sentence (or open-proposition) all of whose instances are true" - logical necessity determines which inferential transitions preserve truth across all possible instances.

Evidence relationships bridge causal and logical necessity by establishing when observed regularities justify theoretical conclusions about unobservable causal structures.

**Information Transmission and Causal Processes**

Information transmission requires genuine causal processes connecting information sources to cognitive systems. "To avoid the theoretical arbitrariness associated with such a position, we must say that (#) is true exactly if there is some actual causal process beginning with E and ending with E*."

Causal processes transmit information by preserving structural relationships across space and time. Sensory perception exemplifies information transmission where environmental structures causally determine perceptual representations.

"Two software-identical units may be physically very different" - this shows how information transmission can preserve abstract structures while varying in physical implementation.

Information transmission fails when causal connections break down or when noise corrupts the transmission process, resulting in unreliable knowledge.**Legitimate vs. Illegitimate Rules of Inference in Scientific Contexts**

Scientific inference requires distinguishing legitimate from illegitimate inference rules based on their correspondence to real dependence-relations. "Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations" - legitimate scientific inference preserves this distinction between genuine logical operations and mere behavioral mimicry.

Illegitimate inference rules generate apparent knowledge that lacks grounding in actual causal or logical necessities. These rules may produce consistent results within limited domains while failing to track genuine dependencies.

"The relation that p bears to phi of p may otherwise be very different from the relation that psi of p bears to p, even though both are consequence relations" - this demonstrates how superficially similar inference patterns can have fundamentally different epistemic statuses.

**The Approximate and Limited Scope Nature of Scientific Principles**

Scientific knowledge is inherently approximate and limited in scope rather than perfectly universal. "First of all, laws are not expressed by regularities. A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge."

This approximation reflects the complex interaction between multiple causal factors in real-world situations. Scientific principles identify dominant patterns while acknowledging exceptions and boundary conditions.

"If a given object's length is given by an irrational number, that object's length cannot be established by measuring that object" - this illustrates how measurement limitations constrain the precision of scientific knowledge.

The limited scope of scientific principles means they apply reliably only within specified conditions and domains of application.

**Self-Modifying Nature of Knowledge and the Impossibility of Complete Knowledge**

Knowledge systems are self-modifying because acquiring new knowledge changes the conceptual frameworks through which we understand reality. "Incoherence arises from trying to satisfy two incompatible systems" - this self-modification can generate internal tensions requiring conceptual revision.

Complete knowledge of the world is impossible because knowledge acquisition itself alters both the knower and the epistemic situation. Each new piece of knowledge potentially transforms our understanding of previously known facts.

"In the final analysis, Chomsky and Kant say that, give or take a few nuances, we are born knowing everything we will ever know" - I reject this view because genuine knowledge acquisition involves genuine discovery rather than mere conceptual unpacking.

The impossibility of complete knowledge also stems from the infinite complexity of causal interactions in the physical world, which exceed any finite cognitive system's capacity for representation.**Laws of Nature as Dispositive Rather Than Exceptionless**

Laws of nature are dispositive rather than exceptionless because they describe tendencies and capacities rather than universal regularities. "First of all, laws are not expressed by regularities. A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge."

This dispositional character means natural laws specify what tends to happen under normal conditions, not what must happen in all circumstances. "The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships."

The distinction between expressing and constituting principled relationships is crucial. Laws describe underlying capacities and dispositions that manifest differently depending on interfering factors and boundary conditions.

**Events vs. Things in Causal Relationships**

Events, not things, enter into causal relations because causation involves changes and processes rather than static objects. "To avoid the theoretical arbitrariness associated with such a position, we must say that (#) is true exactly if there is some actual causal process beginning with E and ending with E*."

Things participate in causal relations only insofar as they undergo events or changes. A rock doesn't cause anything by merely existing - it's the event of the rock's impact that causes the window to break.

"Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations" - this shows how we must distinguish between the events occurring in systems and the systems themselves.

Causal processes are sequences of events connected by energy transfer, information transmission, or other forms of physical interaction. The temporal structure of causation requires events as relata.

**Program-Causes and Overdetermination in Psychology**

Program-causes are structures that predetermine the occurrence of specific determinative events. "A person's having a goal does causal work" - goals function as program-causes by establishing frameworks within which particular behaviors are selected.

In psychology, program-causes operate through creating dispositions and tendencies rather than determining specific outcomes. "The cognitive operations that mediate vision, language-comprehension, and musical ability are subpersonal" - these operations constitute program-causes for conscious experiences.

Overdetermination occurs when multiple program-causes converge to produce the same psychological outcome. "Creatures in whom there are no 'occult processes' are zombies, and zombies cannot be acculturated" - this illustrates how multiple levels of program-causes must operate for genuine psychological functioning.

The relationship between program-causes and their effects involves complex feedback loops and emergent properties that resist simple linear analysis.

**Threshold Effects and INUS Conditions**

Threshold effects involve discontinuous changes requiring the confluence of multiple factors. Unlike gradual causal processes, threshold effects produce qualitative shifts when quantitative accumulation reaches critical points.

INUS conditions are insufficient but non-redundant parts of conditions that are unnecessary but sufficient for their effects. "If so, that's because, while staving off an n-level change, it permits the occurrence of n+ -level changes" - this illustrates how causal factors can simultaneously prevent some effects while enabling others.

Threshold effects demonstrate why simple regularity theories of causation fail to capture the complexity of real causal relationships.**Problems with Counterfactual Theories of Causation**

Counterfactual theories attempt to analyze causation in terms of what would have happened if the cause had not occurred. These theories face insurmountable difficulties when confronted with causal redundancy and overdetermination.

"To avoid the theoretical arbitrariness associated with such a position, we must say that (#) is true exactly if there is some actual causal process beginning with E and ending with E*." This reveals the fundamental problem: counterfactual theories cannot distinguish between genuine causal processes and mere correlations.

The counterfactual approach fails because it relies on possible worlds semantics that cannot capture the actual mechanisms through which causes operate. "A government that permits life-threatening amounts of is not 'small' but simply inadequate" - this demonstrates how counterfactuals often yield incorrect judgments about causal responsibility.

**Causal Redundancy and the Failure of Counterfactual Analysis**

Causal redundancy occurs when multiple alternative causes could produce the same effect, making counterfactual analysis impossible. In such cases, even if the actual cause had not occurred, the effect would still have resulted from backup causes.

"Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations" - this illustrates how genuine causal understanding requires grasping actual mechanisms rather than hypothetical alternatives.

The failure of counterfactual analysis reveals a deeper problem: causation cannot be reduced to logical relationships between propositions. "Pro-state lies" exemplify how causal claims require empirical investigation of actual processes rather than logical manipulation of counterfactuals.

Redundancy cases show that causation involves real physical processes that cannot be captured through purely logical or semantic analysis. "It can be interpreted as an attempt to red pill people about the structure of society" - understanding causation requires recognizing actual power structures and mechanisms.

**Hume's Regularity Theory vs. Conventional Views of Causation**

Hume's regularity theory reduces causation to constant conjunction between types of events. While this approach avoids some metaphysical commitments, it fails to distinguish genuine causal laws from accidental regularities.

"First of all, laws are not expressed by regularities. A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge." This demonstrates why regularity theories cannot account for the dispositional nature of causal powers.

Conventional views of causation invoke necessary connections or productive powers that go beyond mere regularity. However, these views face the challenge of explaining what such connections consist in without appealing to occult qualities.

The tension between Humean and conventional approaches reflects deeper issues about the nature of natural necessity and the relationship between epistemology and metaphysics in causal analysis.

**Transeunt vs. Immanent Causation**

Transeunt causation involves one entity acting upon another distinct entity to produce change. This represents the standard model of efficient causation where causes and effects are numerically distinct.

Immanent causation occurs when an entity acts upon itself or when the cause remains within the effect. "The view that the future is 'fixed' by the present is a defining claim of determinism" - this illustrates how immanent causation operates through internal constraints and dispositions.

The distinction between transeunt and immanent causation reveals different types of causal relationships that require different analytical approaches. "Supposing that the physical world is deterministic and materialism is right, it's hard to see how there could be free will" - this shows how immanent causation relates to questions of agency and self-determination.

Understanding both types of causation is essential for developing adequate theories of mental causation, biological development, and social change.**The Epistemological Foundations of Scientific Knowledge**

My analysis of causation leads directly to fundamental questions about how we acquire knowledge of the physical world. Scientific knowledge presents unique epistemological challenges because it necessarily involves theoretical commitments that go beyond direct observation.

"Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations" - this illustrates how scientific interpretation involves conceptual frameworks that organize our understanding of phenomena. The calculator example shows that theoretical knowledge requires inferential relationships between observable behaviors and underlying structures.

**Theoretical Entities and Observational Evidence**

Scientific theories postulate entities and processes that cannot be directly observed. "AI provides empirically grounded, philosophically illuminating models of scientific reasoning" - this demonstrates how theoretical models can illuminate the structure of inference in scientific contexts.

The relationship between theoretical entities and observational evidence involves complex chains of inference. Each link in these chains must correspond to legitimate dependence-relations, whether logical or causal. "If a given object's length is given by an irrational number, that object's length cannot be established by measuring that object" - this shows the inherent limitations of observational knowledge.

**The Problem of Theoretical Underdetermination**

Multiple theories can account for the same observational data. This underdetermination problem reveals the approximate nature of scientific knowledge. "The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships."

Scientific theories attempt to identify the principled relationships underlying observable regularities. However, our access to these relationships is always mediated through fallible inference patterns. "Two software-identical units may be physically very different" - this illustrates how surface similarities can mask deeper structural differences.

**Conceptual Analysis in Scientific Contexts**

Scientific concepts require careful analysis to determine their logical relationships. "in the final analysis, Chomsky and Kant say that, give or take a few nuances, we are born knowing everything we will ever know" - this highlights how conceptual frameworks shape what we can discover empirically.

Some scientific knowledge involves analytic truths about the relationships between concepts. "The relation that p bears to phi of p may otherwise be very different from the relation that psi of p bears to p, even though both are consequence relations" - this shows how different types of dependence-relations require different analytical approaches.

**Empirical Constraints on Theoretical Knowledge**

While conceptual analysis reveals logical dependence-relations, causal dependence-relations can only be established through sensory experience. "There is a certainty that can attach to knowledge of what we are consciously thinking that cannot attach to knowledge of the external world" - this fundamental asymmetry shapes the structure of scientific knowledge.

The empirical basis of causal knowledge means that scientific theories remain perpetually open to revision. New observations can reveal previously unknown causal relationships or disconfirm existing theoretical commitments.**The Approximate Nature of Scientific Laws**

Scientific principles are inherently approximate rather than exceptionless. "First of all, laws are not expressed by regularities. A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge." This reveals the fundamental difference between idealized theoretical statements and messy empirical reality.

"The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships." I maintain that observed patterns point toward underlying causal structures without perfectly capturing them.

**Self-Modifying Knowledge Systems**

Knowledge systems necessarily modify themselves through their own operations. "Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations" - this illustrates how functional descriptions can remain valid even when the underlying implementation changes.

The impossibility of complete knowledge follows from this self-modifying character. Any attempt to achieve total knowledge would require the system to represent its own representational processes, leading to infinite regress.

**Events as Causal Relata**

Events, not things, enter into genuine causal relationships. "To avoid the theoretical arbitrariness associated with such a position, we must say that (#) is true exactly if there is some actual causal process beginning with E and ending with E*." Causal processes connect specific occurrences rather than persisting objects.

This event-based approach resolves many traditional puzzles about causation. Objects persist through time but cannot literally cause anything - only their states and changes can participate in causal relationships.

**Program-Causes in Psychology**

Psychological explanation often involves program-causes that predetermine specific behavioral outcomes. "A person's having a goal does causal work" - goals function as program-causes by structuring the space of possible actions.

"The cognitive operations that mediate vision, language-comprehension, and musical ability are subpersonal" - these operations constitute program-causes operating below the level of conscious awareness. They create dispositions toward particular cognitive outcomes without determining them mechanistically.

**Threshold Effects and INUS Conditions**

Many causal relationships involve threshold effects requiring the confluence of multiple factors. An INUS condition - an insufficient but non-redundant part of a condition that is unnecessary but sufficient - captures this complexity better than simple necessary-and-sufficient analyses.

"If so, that's because, while staving off an n-level change, it permits the occurrence of n+ -level changes." This shows how causal factors can simultaneously inhibit some effects while enabling others, creating complex threshold dynamics.

**Problems with Counterfactual Theories**

Counterfactual analyses of causation fail systematically due to causal redundancy. When multiple alternative causes could produce the same effect, counterfactuals become indeterminate rather than illuminating.

"If a given object's length is given by an irrational number, that object's length cannot be established by measuring that object." This measurement limitation parallels the fundamental inadequacy of counterfactual approaches to capture genuine causal relationships.**Causal Redundancy and Counterfactual Failure**

Consider a firing squad scenario where multiple marksmen shoot simultaneously. Each bullet would be sufficient to kill the victim, yet counterfactual analysis breaks down completely. If marksman A hadn't fired, the victim would still be dead from marksman B's bullet.

"To avoid the theoretical arbitrariness associated with such a position, we must say that (#) is true exactly if there is some actual causal process beginning with E and ending with E*." Counterfactuals cannot capture this requirement for actual causal processes because they focus on hypothetical scenarios rather than real connections.

The problem runs deeper than mere technical difficulties. Causal redundancy is ubiquitous in complex systems. Multiple neural pathways can mediate the same cognitive function. Multiple economic factors can produce the same market outcome. Multiple social pressures can generate identical behavioral patterns.

**Hume's Regularity Theory vs. Conventional Views**

"The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships." This captures my fundamental disagreement with pure regularity theories.

Hume's analysis reduces causation to constant conjunction, but this misses the crucial distinction between mere correlation and genuine dependence-relations. Regularities are symptoms of causal structure, not causal structure itself.

"First of all, laws are not expressed by regularities. A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge." This shows why regularity theory fails - genuine causal laws are dispositive rather than exceptionless.

**Transeunt vs. Immanent Causation**

I distinguish between transeunt causation (where cause and effect are distinct events) and immanent causation (where the cause is a substance or thing that produces changes in itself). Most philosophical discussions focus exclusively on transeunt causation.

"Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations." This illustrates how we can have genuine causal understanding even when the underlying mechanisms differ from our conceptual frameworks.

Immanent causation involves substances exercising their causal powers. A magnet attracts iron filings through immanent causation - the magnet's magnetic field is not a separate event but an ongoing manifestation of the magnet's nature.

"Two software-identical units may be physically very different." This shows how the same causal structure can be realized in multiple physical substrates, supporting the distinction between causal and physical levels of description.

The failure to recognize immanent causation leads to endless regresses in causal analysis. Every transeunt causal relationship presupposes substances with the power to initiate causal chains.**Events vs. Things in Causal Relationships**

Events, not things, are the proper relata of causal relations. "A person's having a goal does causal work" - this shows how psychological events function causally. The goal-having event, not the person as a substance, enters into causal relationships with other events.

"The view that the future is 'fixed' by the present is a defining claim of determinism." This fixing relationship holds between events at different times. Present events causally determine future events through chains of transeunt causation.

When we say "the rock broke the window," we're speaking loosely. Strictly, it's the rock's hitting the window that caused the window's breaking. Things participate in causation only by being involved in events.

**Program-Causes and Overdetermination in Psychology**

Program-causes are structures that predetermine the occurrence of specific determinative events. "The cognitive operations that mediate vision, language-comprehension, and musical ability are subpersonal" - these operations function as program-causes for conscious experiences.

"AI provides empirically grounded, philosophically illuminating models of scientific reasoning." These models reveal how program-causes operate in cognitive systems. The program structure determines which specific computational events will occur.

Overdetermination occurs when multiple program-causes could produce the same effect. "Supposing that the physical world is deterministic and materialism is right, it's hard to see how there could be free will" - this reflects how multiple levels of program-causes (physical and psychological) might overdetermine behavior.

**Threshold Effects and INUS Conditions**

Threshold effects involve discontinuous changes requiring the confluence of multiple factors. "Incoherence arises from trying to satisfy two incompatible systems" - this exemplifies how threshold effects operate in rational agency.

INUS conditions are insufficient but non-redundant parts of conditions that are unnecessary but sufficient. A spark is an INUS condition for an explosion - insufficient alone, but non-redundant within the total sufficient condition that includes oxygen and fuel.

"If so, that's because, while staving off an n-level change, it permits the occurrence of n+ -level changes." This illustrates how causal systems involve complex threshold relationships across different organizational levels.

Most real causation involves INUS conditions rather than simple sufficient conditions. "But if individual courses had guaranteed meanings, and if it was always determinate what those meanings were, then passing so much as a single class would be definite proof of a definite kind of merit" - this shows how educational achievement involves multiple INUS conditions.

**Problems with Counterfactual Theories of Causation**

Counterfactual theories claim that A causes B if B would not have occurred without A. "To avoid the theoretical arbitrariness associated with such a position, we must say that (#) is true exactly if there is some actual causal process beginning with E and ending with E*."

This approach faces the problem of causal redundancy. Multiple alternative causes often exist for the same effect, making counterfactuals false even when genuine causation occurs.**Causal Redundancy and the Failure of Counterfactual Analysis**

Counterfactual theories collapse when confronted with overdetermined situations. Consider a firing squad where multiple shooters fire simultaneously at the condemned. Each bullet would be fatal, yet the counterfactual "if shooter A hadn't fired, the person would still be alive" is false.

"The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships." This captures why counterfactuals miss the deeper causal structure.

Causal redundancy is pervasive in complex systems. Backup mechanisms, alternative pathways, and multiple sufficient conditions create situations where removing any single cause wouldn't prevent the effect. The counterfactual analysis therefore systematically misidentifies genuine causal relationships.

**Hume's Regularity Theory vs. Conventional Views of Causation**

Hume reduced causation to constant conjunction - mere regular succession of events. "First of all, laws are not expressed by regularities. A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge."

This demonstrates Hume's error. Real causal laws involve dispositions and powers, not perfect concomitances. Collisions don't always produce displacement because causal relationships are more complex than simple regularities suggest.

"in the final analysis, Chomsky and Kant say that, give or take a few nuances, we are born knowing everything we will ever know." This relates to how we recognize causal patterns - through innate cognitive structures that go beyond mere regularity detection.

Modern regularity theories face the same problems. They cannot distinguish genuine causal sequences from accidental correlations. "Calculators are not themselves performing arithmetical operations, but their behavior is still appropriately understood in terms of such operations" - this shows how functional relationships transcend mere behavioral regularities.

**Transeunt vs. Immanent Causation**

Transeunt causation involves one entity acting upon another distinct entity. A hammer striking a nail exemplifies transeunt causation - the cause and effect involve separate objects in causal interaction.

Immanent causation occurs within a single entity. An agent's decision causing their action represents immanent causation - the same entity serves as both cause and effect through internal causal processes.

"A person's having a goal does causal work" - this illustrates immanent causation where psychological states within an agent generate behavioral outcomes. The causal relationship operates within the unified structure of personal agency.

"Supposing that the physical world is deterministic and materialism is right, it's hard to see how there could be free will." This tension arises because free will seems to require immanent causation - agents causing their own actions - while determinism suggests only transeunt causation operates.

The distinction matters for understanding personal responsibility and rational agency. Immanent causation preserves the integrity of agents as unified causal systems, while transeunt causation fragments agency into external determinations.**The Approximate Nature of Scientific Knowledge**

Scientific principles never achieve perfect accuracy or unlimited scope. "First of all, laws are not expressed by regularities. A collision may or may not displace an object. It may be destroy it. It may not destroy it, but may fail to make it budge." This reveals why scientific laws cannot be understood as exceptionless regularities.

Physical laws describe tendencies and dispositions rather than invariant correlations. Newton's laws work excellently for medium-sized objects at moderate velocities, but break down at quantum scales and relativistic speeds. This isn't a failure of science - it reflects the inherently approximate character of all scientific knowledge.

"The physical world is characterized by many regularities (leaving aside the explanatorily sterile ones just discussed). But presumably these regularities express, and do not constitute, the existence of principled relationships." Scientific laws point toward underlying causal structures without perfectly capturing them.

**Self-Modifying Knowledge Systems**

Knowledge transforms itself through its own operations. Each new discovery potentially revises our understanding of previous discoveries. This creates a dynamic epistemic situation where complete knowledge becomes impossible in principle.

"AI provides empirically grounded, philosophically illuminating models of scientific reasoning" - artificial intelligence systems demonstrate how knowledge can recursively improve its own methods. Machine learning algorithms modify their own inference procedures based on performance feedback.

"A genuine 'logic of discovery' is possible and can be revealed by studying AI systems." These systems show how knowledge acquisition involves self-modifying processes that cannot be fully predicted in advance.

The impossibility of complete knowledge follows from this self-modifying character. Any complete knowledge system would need to predict its own future modifications, creating logical paradoxes similar to those in computability theory.

**Laws as Dispositive Rather Than Exceptionless**

Natural laws describe what typically happens under standard conditions, not what must happen universally. "Two software-identical units may be physically very different" - this shows how identical causal programs can manifest differently in different physical contexts.

Gravitational attraction operates as a disposition - massive objects tend to attract each other. But this tendency can be overwhelmed by electromagnetic forces, nuclear forces, or quantum effects. The law describes a real causal power without guaranteeing specific outcomes.

"If so, that's because, while staving off an n-level change, it permits the occurrence of n+ -level changes." Complex systems exhibit hierarchical organization where laws operating at one level can be modified by processes at higher levels.

This dispositive understanding explains why scientific prediction remains probabilistic. Laws describe genuine causal powers while acknowledging that multiple powers can interact in unpredictable ways.

**Events vs. Things in Causal Relations**

Causation relates events, not objects. When we say "the hammer caused the dent," we really mean the event of the hammer striking caused the event of the dent forming. Objects participate in causal relations only by undergoing changes or events.

"The view that the future is 'fixed' by the present is a defining claim of determinism" - but determinism operates through event-sequences, not through static object-relations. Present events determine future events through causal processes unfolding in time.

This event-based understanding clarifies causal asymmetry. Events have temporal locations and durations, creating the directional flow essential to causation. Objects exist across time but don't exhibit the temporal asymmetry that characterizes causal relationships.